---
sidebar_position: 1
slug: /
---

# Welcome To EGO4D!

EGO4D is the world's largest egocentric (first person) video ML dataset and benchmark suite, with 3,600 hrs (and counting) of densely narrated video and a wide range of [annotations](./data/annotation-guidelines.md) across five new [benchmark tasks](./benchmarks/overview.md).  It covers hundreds of scenarios (household, outdoor, workplace, leisure, etc.) of daily life activity captured in-the-wild by 926 unique camera wearers from 74 worldwide locations and 9 different countries.  Portions of the video are accompanied by audio, 3D meshes of the environment, eye gaze, stereo, and/or synchronized videos from multiple egocentric cameras at the same event.  The approach to data collection was designed to uphold rigorous privacy and ethics standards with consenting participants and robust de-identification procedures where relevant.

[Start Here](./start-here.md) for instructions on how to access the dataset by accepting the terms of our license agreement.

[Read the paper here](https://arxiv.org/abs/2110.07058) for a more complete introduction.

[Read about the benchmarks here](./benchmarks/overview.md) for details on the specific tasks and annotations.

:::note Paper Update Pending
Please note the current arxiv paper is based on an earlier version of the dataset and an update will be available shortly with numbers reflecting minor changes to the final dataset.
:::