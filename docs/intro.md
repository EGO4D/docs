---
sidebar_position: 1
slug: /
---

:::note Forum/Visualization Release + v1.1 Update Pending
Note that the [Ego4D forum](https://discuss.ego4d-data.org/) and [visualization tool](./viz.md) are now available.  Also note that a dataset update is pending addressing a number of small annotation issues.  Full details will be provided [here](./data/updates.md) and at the forum after the current challenge round locks on June 1.
:::

# Welcome To EGO4D!

EGO4D is the world's largest egocentric (first person) video ML dataset and benchmark suite, with 3,600 hrs (and counting) of densely narrated video and a wide range of [annotations](./data/annotation-guidelines.md) across five new [benchmark tasks](./benchmarks/overview.md).  It covers hundreds of scenarios (household, outdoor, workplace, leisure, etc.) of daily life activity captured in-the-wild by 926 unique camera wearers from 74 worldwide locations and 9 different countries.  Portions of the video are accompanied by audio, 3D meshes of the environment, eye gaze, stereo, and/or synchronized videos from multiple egocentric cameras at the same event.  The approach to data collection was designed to uphold rigorous privacy and ethics standards with consenting participants and robust de-identification procedures where relevant.

[Start Here](./start-here.md) for instructions on how to access the dataset by accepting the terms of our license agreement.

[Read the paper here](https://arxiv.org/abs/2110.07058) for a more complete introduction.

[Read about the benchmarks here](./benchmarks/overview.md) for details on the specific tasks and annotations.

[Vist our forum](https://discuss.ego4d-data.org/) or [contact us](./contact.md) to ask questions, make suggestions or discuss Ego4D or related research.
