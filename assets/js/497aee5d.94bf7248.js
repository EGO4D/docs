"use strict";(self.webpackChunkdocs=self.webpackChunkdocs||[]).push([[910],{3905:function(e,r,t){t.d(r,{Zo:function(){return d},kt:function(){return m}});var n=t(7294);function i(e,r,t){return r in e?Object.defineProperty(e,r,{value:t,enumerable:!0,configurable:!0,writable:!0}):e[r]=t,e}function a(e,r){var t=Object.keys(e);if(Object.getOwnPropertySymbols){var n=Object.getOwnPropertySymbols(e);r&&(n=n.filter((function(r){return Object.getOwnPropertyDescriptor(e,r).enumerable}))),t.push.apply(t,n)}return t}function o(e){for(var r=1;r<arguments.length;r++){var t=null!=arguments[r]?arguments[r]:{};r%2?a(Object(t),!0).forEach((function(r){i(e,r,t[r])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(t)):a(Object(t)).forEach((function(r){Object.defineProperty(e,r,Object.getOwnPropertyDescriptor(t,r))}))}return e}function c(e,r){if(null==e)return{};var t,n,i=function(e,r){if(null==e)return{};var t,n,i={},a=Object.keys(e);for(n=0;n<a.length;n++)t=a[n],r.indexOf(t)>=0||(i[t]=e[t]);return i}(e,r);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);for(n=0;n<a.length;n++)t=a[n],r.indexOf(t)>=0||Object.prototype.propertyIsEnumerable.call(e,t)&&(i[t]=e[t])}return i}var s=n.createContext({}),l=function(e){var r=n.useContext(s),t=r;return e&&(t="function"==typeof e?e(r):o(o({},r),e)),t},d=function(e){var r=l(e.components);return n.createElement(s.Provider,{value:r},e.children)},u={inlineCode:"code",wrapper:function(e){var r=e.children;return n.createElement(n.Fragment,{},r)}},p=n.forwardRef((function(e,r){var t=e.components,i=e.mdxType,a=e.originalType,s=e.parentName,d=c(e,["components","mdxType","originalType","parentName"]),p=l(t),m=i,h=p["".concat(s,".").concat(m)]||p[m]||u[m]||a;return t?n.createElement(h,o(o({ref:r},d),{},{components:t})):n.createElement(h,o({ref:r},d))}));function m(e,r){var t=arguments,i=r&&r.mdxType;if("string"==typeof e||i){var a=t.length,o=new Array(a);o[0]=p;var c={};for(var s in r)hasOwnProperty.call(r,s)&&(c[s]=r[s]);c.originalType=e,c.mdxType="string"==typeof e?e:i,o[1]=c;for(var l=2;l<a;l++)o[l]=t[l];return n.createElement.apply(null,o)}return n.createElement.apply(null,t)}p.displayName="MDXCreateElement"},9988:function(e,r,t){t.r(r),t.d(r,{frontMatter:function(){return c},contentTitle:function(){return s},metadata:function(){return l},toc:function(){return d},default:function(){return p}});var n=t(7462),i=t(3366),a=(t(7294),t(3905)),o=["components"],c={sidebar_position:1},s="Benchmarks Overview",l={unversionedId:"benchmarks/overview",id:"benchmarks/overview",isDocsHomePage:!1,title:"Benchmarks Overview",description:"Episodic Memory",source:"@site/docs/benchmarks/overview.md",sourceDirName:"benchmarks",slug:"/benchmarks/overview",permalink:"/docs/benchmarks/overview",editUrl:"https://https://ego4d-data.org/docs/benchmarks/overview.md",tags:[],version:"current",sidebarPosition:1,frontMatter:{sidebar_position:1},sidebar:"tutorialSidebar",previous:{title:"Start Here",permalink:"/docs/start-here"},next:{title:"Episodic Memory",permalink:"/docs/benchmarks/episodic-memory"}},d=[{value:"Episodic Memory",id:"episodic-memory",children:[],level:2},{value:"Hands and Objects",id:"hands-and-objects",children:[],level:2},{value:"Forecasting",id:"forecasting",children:[],level:2},{value:"Audio-Visual Diarization",id:"audio-visual-diarization",children:[],level:2},{value:"Social Interactions",id:"social-interactions",children:[],level:2}],u={toc:d};function p(e){var r=e.components,t=(0,i.Z)(e,o);return(0,a.kt)("wrapper",(0,n.Z)({},u,t,{components:r,mdxType:"MDXLayout"}),(0,a.kt)("h1",{id:"benchmarks-overview"},"Benchmarks Overview"),(0,a.kt)("h2",{id:"episodic-memory"},(0,a.kt)("a",{parentName:"h2",href:"/docs/benchmarks/episodic-memory"},"Episodic Memory")),(0,a.kt)("p",null,"The Episodic Memory task aims to make past video queryable and requires localizing where the answer can be seen within the user\u2019s past video. "),(0,a.kt)("h2",{id:"hands-and-objects"},(0,a.kt)("a",{parentName:"h2",href:"/docs/benchmarks/hands-and-objects"},"Hands and Objects")),(0,a.kt)("p",null,"Hands & Objects aims to understand the camera-wearers present activity in terms of interactions with objects."),(0,a.kt)("h2",{id:"forecasting"},(0,a.kt)("a",{parentName:"h2",href:"/docs/benchmarks/forecasting"},"Forecasting")),(0,a.kt)("p",null,"Forecasting movements and interactions requires comprehending the camera wearer\u2019s intention."),(0,a.kt)("h2",{id:"audio-visual-diarization"},(0,a.kt)("a",{parentName:"h2",href:"/docs/benchmarks/av-diarization"},"Audio-Visual Diarization")),(0,a.kt)("p",null,"The Audio-Visual Diarization tasks involve localizing and tracking of the participants, detecting each speaker's activity, and transcribing all speech content."),(0,a.kt)("h2",{id:"social-interactions"},(0,a.kt)("a",{parentName:"h2",href:"/docs/benchmarks/social"},"Social Interactions")),(0,a.kt)("p",null,"The Social benchmark focuses on multimodal understanding of conversational interactions via attention and speech."))}p.isMDXComponent=!0}}]);