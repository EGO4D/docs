"use strict";(self.webpackChunkdocs=self.webpackChunkdocs||[]).push([[736],{3905:(e,t,o)=>{o.d(t,{Zo:()=>p,kt:()=>h});var n=o(7294);function a(e,t,o){return t in e?Object.defineProperty(e,t,{value:o,enumerable:!0,configurable:!0,writable:!0}):e[t]=o,e}function i(e,t){var o=Object.keys(e);if(Object.getOwnPropertySymbols){var n=Object.getOwnPropertySymbols(e);t&&(n=n.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),o.push.apply(o,n)}return o}function r(e){for(var t=1;t<arguments.length;t++){var o=null!=arguments[t]?arguments[t]:{};t%2?i(Object(o),!0).forEach((function(t){a(e,t,o[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(o)):i(Object(o)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(o,t))}))}return e}function s(e,t){if(null==e)return{};var o,n,a=function(e,t){if(null==e)return{};var o,n,a={},i=Object.keys(e);for(n=0;n<i.length;n++)o=i[n],t.indexOf(o)>=0||(a[o]=e[o]);return a}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(n=0;n<i.length;n++)o=i[n],t.indexOf(o)>=0||Object.prototype.propertyIsEnumerable.call(e,o)&&(a[o]=e[o])}return a}var l=n.createContext({}),d=function(e){var t=n.useContext(l),o=t;return e&&(o="function"==typeof e?e(t):r(r({},t),e)),o},p=function(e){var t=d(e.components);return n.createElement(l.Provider,{value:t},e.children)},c="mdxType",m={inlineCode:"code",wrapper:function(e){var t=e.children;return n.createElement(n.Fragment,{},t)}},u=n.forwardRef((function(e,t){var o=e.components,a=e.mdxType,i=e.originalType,l=e.parentName,p=s(e,["components","mdxType","originalType","parentName"]),c=d(o),u=a,h=c["".concat(l,".").concat(u)]||c[u]||m[u]||i;return o?n.createElement(h,r(r({ref:t},p),{},{components:o})):n.createElement(h,r({ref:t},p))}));function h(e,t){var o=arguments,a=t&&t.mdxType;if("string"==typeof e||a){var i=o.length,r=new Array(i);r[0]=u;var s={};for(var l in t)hasOwnProperty.call(t,l)&&(s[l]=t[l]);s.originalType=e,s[c]="string"==typeof e?e:a,r[1]=s;for(var d=2;d<i;d++)r[d]=o[d];return n.createElement.apply(null,r)}return n.createElement.apply(null,o)}u.displayName="MDXCreateElement"},3273:(e,t,o)=>{o.r(t),o.d(t,{assets:()=>l,contentTitle:()=>r,default:()=>c,frontMatter:()=>i,metadata:()=>s,toc:()=>d});var n=o(7462),a=(o(7294),o(3905));const i={sidebar_position:3},r="Videos",s={unversionedId:"data/videos",id:"data/videos",title:"Videos",description:"Videos are sourced from a variety of devices, locations and participants across a wide range of",source:"@site/docs/data/videos.md",sourceDirName:"data",slug:"/data/videos",permalink:"/docs/data/videos",draft:!1,tags:[],version:"current",sidebarPosition:3,frontMatter:{sidebar_position:3},sidebar:"tutorialSidebar",previous:{title:"Metadata",permalink:"/docs/data/metadata"},next:{title:"Gaze",permalink:"/docs/data/gaze"}},l={},d=[{value:"Background",id:"background",level:2},{value:"Non-Obvious Properties",id:"non-obvious-properties",level:3},{value:"Canonical Videos",id:"canonical-videos",level:2},{value:"How They Are Constructed",id:"how-they-are-constructed",level:3},{value:"Canonical Clips",id:"canonical-clips",level:2},{value:"Video Components",id:"video-components",level:2},{value:"Attributes of the Data",id:"attributes-of-the-data",level:3},{value:"Inconsistent Properties",id:"inconsistent-properties",level:4}],p={toc:d};function c(e){let{components:t,...o}=e;return(0,a.kt)("wrapper",(0,n.Z)({},p,o,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("h1",{id:"videos"},"Videos"),(0,a.kt)("p",null,"Videos are sourced from a variety of devices, locations and participants across a wide range of\nscenarios.  The original source videos (",(0,a.kt)("strong",{parentName:"p"},"video components"),") that were captured by university participants were composed into standardized, full length videos (",(0,a.kt)("strong",{parentName:"p"},"canonical videos"),", the primary videos in the dataset).  Shorter clips of the longer videos were then annotated to generate the dataset annotations, and finally shorter ",(0,a.kt)("strong",{parentName:"p"},"canonical clips")," were formed from the videos and exported with the dataset."),(0,a.kt)("p",null,"Accordingly, video data is available in three forms for the dataset. Each form can be identified with a unique identifier string (uuid4):"),(0,a.kt)("ol",null,(0,a.kt)("li",{parentName:"ol"},(0,a.kt)("strong",{parentName:"li"},"Canonical videos")," - Derived from the video components"),(0,a.kt)("li",{parentName:"ol"},(0,a.kt)("strong",{parentName:"li"},"Canonical Clips")," - Clips associated to specific ",(0,a.kt)("a",{parentName:"li",href:"/docs/data/annotations-schemas"},"annotation")," data and derived from the canonical videos."),(0,a.kt)("li",{parentName:"ol"},"Video Components - The raw components used to construct the videos and primary provided as an ancillarly export for thoroughness.")),(0,a.kt)("p",null,"The canonical videos or the canonical clips are the ",(0,a.kt)("strong",{parentName:"p"},"recomended")," way to use the dataset."),(0,a.kt)("h2",{id:"background"},"Background"),(0,a.kt)("p",null,"Each video, in the dataset, is in a video container (such as mp4, webm, etc.)\nand may have multiple streams. In other words, for a video we have the\nfollowing:"),(0,a.kt)("ol",null,(0,a.kt)("li",{parentName:"ol"},"The container"),(0,a.kt)("li",{parentName:"ol"},"Video stream"),(0,a.kt)("li",{parentName:"ol"},"Audio stream")),(0,a.kt)("h3",{id:"non-obvious-properties"},"Non-Obvious Properties"),(0,a.kt)("p",null,"It is possible for the following properties to be true:"),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},"The container ends ",(0,a.kt)("strong",{parentName:"li"},"before")," or ",(0,a.kt)("strong",{parentName:"li"},"after")," one or both of the stream\nends. In the case that the:",(0,a.kt)("ul",{parentName:"li"},(0,a.kt)("li",{parentName:"ul"},"Video stream ends before: blank frames are played"),(0,a.kt)("li",{parentName:"ul"},"Video stream ends after: video players will continue to play the stream"))),(0,a.kt)("li",{parentName:"ul"},"The audio stream starts after the video stream starts"),(0,a.kt)("li",{parentName:"ul"},"The video stream starts after the audio stream starts")),(0,a.kt)("p",null,"To be clear, in instances where raw components is contained within the\nvideo container (by multiple frames), it has no frame data in these\nregions."),(0,a.kt)("p",null,"These properties can be fixed by either:"),(0,a.kt)("ol",null,(0,a.kt)("li",{parentName:"ol"},"Remuxing the video file to another MP4 container, i.e. ",(0,a.kt)("inlineCode",{parentName:"li"},"ffmpeg -i in.mp4 -c copy out.mp4")),(0,a.kt)("li",{parentName:"ol"},"Compressing the video file")),(0,a.kt)("h2",{id:"canonical-videos"},"Canonical Videos"),(0,a.kt)("p",null,"The purpose of the canonical videos is to normalize the videos in\norder to simplify the usage of the dataset, and are the primary way we expect\nusers to consume the dataset."),(0,a.kt)("p",null,"Canonical videos are normalized videos constructed from the ",(0,a.kt)("a",{parentName:"p",href:"#video-components"},"video\ncomponents"),", concatenated together with the following\ncharacteristics:"),(0,a.kt)("ol",null,(0,a.kt)("li",{parentName:"ol"},"30FPS"),(0,a.kt)("li",{parentName:"ol"},"Sample Aspect Ratio (SAR) set to 1:1"),(0,a.kt)("li",{parentName:"ol"},"Audio set to AAC")),(0,a.kt)("p",null,"Each canonical video is:"),(0,a.kt)("ol",null,(0,a.kt)("li",{parentName:"ol"},"Compressed with a two-pass VP9 (CRF of 41)"),(0,a.kt)("li",{parentName:"ol"},"Components have their video streams trimmed. This means that:",(0,a.kt)("ol",{parentName:"li"},(0,a.kt)("li",{parentName:"ol"},"Canonical videos are a continious stream of video frames,\ni.e. if a video component starts at ",(0,a.kt)("inlineCode",{parentName:"li"},"t > 0")," the initial part of\nthe video component is removed."),(0,a.kt)("li",{parentName:"ol"},"If the audio exceeds the video stream, the audio is trimmed")))),(0,a.kt)("p",null,"FFMPEG is used for all processing."),(0,a.kt)("h3",{id:"how-they-are-constructed"},"How They Are Constructed"),(0,a.kt)("p",null,"Each video component is first compressed with a video filter to\nnormalize all properties outside of audio. During compression, videos\nare seeked to ",(0,a.kt)("inlineCode",{parentName:"p"},"vs")," where ",(0,a.kt)("inlineCode",{parentName:"p"},"vs")," is the start time of the video stream,\nsuch that components can be trimmed to the video stream."),(0,a.kt)("p",null,"After each component for a video has been compressed, they run through\nthe following steps:"),(0,a.kt)("ol",null,(0,a.kt)("li",{parentName:"ol"},"A remux of the container is performed to encode the audio to AAC or\nnormalize inconsistent audio rates"),(0,a.kt)("li",{parentName:"ol"},"FFMPEG concat demuxer is used to combine the components together\ninto one video file (with ",(0,a.kt)("a",{parentName:"li",href:"https://ffmpeg.org/ffmpeg-formats.html#Options"},(0,a.kt)("inlineCode",{parentName:"a"},"-segment_time_metadata 1")),")")),(0,a.kt)("h2",{id:"canonical-clips"},"Canonical Clips"),(0,a.kt)("p",null,"TODO"),(0,a.kt)("h2",{id:"video-components"},"Video Components"),(0,a.kt)("p",null,"Majoriy of the video components in the dataset have been compressed\nand have had their metadata stripped prior to them being used. Hence\nin many cases where there was originally IMU or GPU metadata there no\nlonger is."),(0,a.kt)("p",null,"The raw video component data is available through ",(0,a.kt)("strong",{parentName:"p"},(0,a.kt)("a",{parentName:"strong",href:"https://github.com/facebookresearch/Ego4d/blob/main/ego4d/cli/README.md"},"EGO4D\nCLI")),"\nwith the ",(0,a.kt)("inlineCode",{parentName:"p"},"--raw_components")," option."),(0,a.kt)("h3",{id:"attributes-of-the-data"},"Attributes of the Data"),(0,a.kt)("h4",{id:"inconsistent-properties"},"Inconsistent Properties"),(0,a.kt)("ol",null,(0,a.kt)("li",{parentName:"ol"},"Video timebases (base numerator/denominator)"),(0,a.kt)("li",{parentName:"ol"},"Audio timebases (base numerator/denominator)"),(0,a.kt)("li",{parentName:"ol"},"FPS"),(0,a.kt)("li",{parentName:"ol"},"Audio rate (32KHz vs 48KHz)"),(0,a.kt)("li",{parentName:"ol"},"Audio channel layout (mono vs. audio)")),(0,a.kt)("p",null,"Additionally many video components have ",(0,a.kt)("a",{parentName:"p",href:"#non-obvious-properties"},"non-obvious\nproperties"),"."),(0,a.kt)("p",null,"TODO: stats"))}c.isMDXComponent=!0}}]);