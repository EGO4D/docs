"use strict";(self.webpackChunkdocs=self.webpackChunkdocs||[]).push([[53],{1109:e=>{e.exports=JSON.parse('{"pluginId":"default","version":"current","label":"Next","banner":null,"badge":false,"noIndex":false,"className":"docs-version-current","isLast":true,"docsSidebars":{"tutorialSidebar":[{"type":"link","label":"Welcome To EGO4D!","href":"/docs/","docId":"intro"},{"type":"link","label":"Start Here","href":"/docs/start-here","docId":"start-here"},{"type":"category","label":"Data","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"Annotation Guidelines","href":"/docs/data/annotation-guidelines","docId":"data/annotation-guidelines"},{"type":"link","label":"Metadata","href":"/docs/data/metadata","docId":"data/metadata"},{"type":"link","label":"Videos","href":"/docs/data/videos","docId":"data/videos"},{"type":"link","label":"Gaze","href":"/docs/data/gaze","docId":"data/gaze"},{"type":"link","label":"IMU","href":"/docs/data/imu","docId":"data/imu"},{"type":"link","label":"Features","href":"/docs/data/features","docId":"data/features"},{"type":"link","label":"Annotation Schemas","href":"/docs/data/annotations-schemas","docId":"data/annotations-schemas"},{"type":"link","label":"EgoTracks","href":"/docs/data/egotracks","docId":"data/egotracks"},{"type":"link","label":"Unprocessed Data","href":"/docs/data/unprocessed_data","docId":"data/unprocessed_data"}]},{"type":"category","label":"Benchmark Tasks","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"Benchmarks Overview","href":"/docs/benchmarks/overview","docId":"benchmarks/overview"},{"type":"link","label":"Episodic Memory","href":"/docs/benchmarks/episodic-memory","docId":"benchmarks/episodic-memory"},{"type":"link","label":"Forecasting","href":"/docs/benchmarks/forecasting","docId":"benchmarks/forecasting"},{"type":"link","label":"Hand & Object Interactions","href":"/docs/benchmarks/hands-and-objects","docId":"benchmarks/hands-and-objects"},{"type":"link","label":"AV Diarization","href":"/docs/benchmarks/av-diarization","docId":"benchmarks/av-diarization"},{"type":"link","label":"Social Interactions","href":"/docs/benchmarks/social","docId":"benchmarks/social"}]},{"type":"link","label":"CLI Tool","href":"/docs/CLI","docId":"CLI"},{"type":"link","label":"Visualization Tool","href":"/docs/viz","docId":"viz"},{"type":"link","label":"Privacy and Ethics","href":"/docs/privacy","docId":"privacy"},{"type":"link","label":"Model Zoo","href":"/docs/model-zoo","docId":"model-zoo"},{"type":"link","label":"Ego4D Challenge 2023","href":"/docs/challenge","docId":"challenge"},{"type":"link","label":"Updates","href":"/docs/updates","docId":"updates"},{"type":"link","label":"FAQ","href":"/docs/FAQ","docId":"FAQ"},{"type":"link","label":"Contact Us","href":"/docs/contact","docId":"contact"}]},"docs":{"benchmarks/av-diarization":{"id":"benchmarks/av-diarization","title":"AV Diarization","description":"Benchmark Repo//github.com/EGO4D/audio-visual","sidebar":"tutorialSidebar"},"benchmarks/episodic-memory":{"id":"benchmarks/episodic-memory","title":"Episodic Memory","description":"Benchmark Repo//github.com/EGO4D/episodic-memory","sidebar":"tutorialSidebar"},"benchmarks/forecasting":{"id":"benchmarks/forecasting","title":"Forecasting","description":"Benchmark Repo//github.com/EGO4D/forecasting","sidebar":"tutorialSidebar"},"benchmarks/hands-and-objects":{"id":"benchmarks/hands-and-objects","title":"Hand & Object Interactions","description":"Benchmark Repo//github.com/EGO4D/hands-and-objects","sidebar":"tutorialSidebar"},"benchmarks/overview":{"id":"benchmarks/overview","title":"Benchmarks Overview","description":"Episodic Memory","sidebar":"tutorialSidebar"},"benchmarks/social":{"id":"benchmarks/social","title":"Social Interactions","description":"Benchmark Repo//github.com/EGO4D/social-interactions","sidebar":"tutorialSidebar"},"challenge":{"id":"challenge","title":"Ego4D Challenge 2023","description":"Overview","sidebar":"tutorialSidebar"},"CLI":{"id":"CLI","title":"CLI Tool","description":"The Ego4D CLI can be installed via pip and provides access to the Ego4D datasets.","sidebar":"tutorialSidebar"},"contact":{"id":"contact","title":"Contact Us","description":"We\'d love to hear from you and have you as part of the EGO4D community!","sidebar":"tutorialSidebar"},"data/annotation-guidelines":{"id":"data/annotation-guidelines","title":"Annotation Guidelines","description":"This page contains context mostly on the annotation guidelines used in each tasks.  Please also see annotations for the specific formats and benchmark tasks for more detail on the tasks themselves.  And please read the paper here for the most comprehensive introduction.","sidebar":"tutorialSidebar"},"data/annotations-schemas":{"id":"data/annotations-schemas","title":"Annotation Schemas","description":"Once you download the annotations with the cli, you\'ll have a set of json files. Here are their schemas for quick reference - see annotation guidelines and benchmark tasks for more information on what the fields represent.","sidebar":"tutorialSidebar"},"data/egotracks":{"id":"data/egotracks","title":"EgoTracks","description":"EgoTracks: A Long-term Egocentric Visual Object Tracking Dataset","sidebar":"tutorialSidebar"},"data/features":{"id":"data/features","title":"Features","description":"The features have been updated as of 2022-06-07. Please re-download them if you","sidebar":"tutorialSidebar"},"data/gaze":{"id":"data/gaze","title":"Gaze","description":"Gaze is available in two forms:","sidebar":"tutorialSidebar"},"data/imu":{"id":"data/imu","title":"IMU","description":"The IMU data is normalized to a flat CSV file per","sidebar":"tutorialSidebar"},"data/metadata":{"id":"data/metadata","title":"Metadata","description":"Top level metadata for the set can be found primarily through ego4d.json available via the EGO4D CLI with the --metdata option (or enabled by default with any other primary dataset).","sidebar":"tutorialSidebar"},"data/unprocessed_data":{"id":"data/unprocessed_data","title":"Unprocessed Data","description":"1. Usage of raw data is not recommended unless you know what you\'re","sidebar":"tutorialSidebar"},"data/videos":{"id":"data/videos","title":"Videos","description":"Videos are sourced from a variety of devices, locations and participants across a wide range of","sidebar":"tutorialSidebar"},"FAQ":{"id":"FAQ","title":"FAQ","description":"Note that many questions may have already been answered on the forum or github issues for the primary github repo or for the benchmark specific repos.","sidebar":"tutorialSidebar"},"intro":{"id":"intro","title":"Welcome To EGO4D!","description":"The Ego4D v2.0 update is now publicly available.","sidebar":"tutorialSidebar"},"model-zoo":{"id":"model-zoo","title":"Model Zoo","description":"This zoo will hold general pre-trained first-person models, as well as benchmark task-specific ones.","sidebar":"tutorialSidebar"},"privacy":{"id":"privacy","title":"Privacy and Ethics","description":"From the onset, privacy and ethics standards were critical to this data collection effort. Each partner was responsible for developing a policy. While specifics vary per site, common guidelines have been followed. Please refer to our statement by members of the consortium on issues of privacy and ethics for further details. Our standards typically require that video be captured in controlled environments with informed consent or else in public where faces and other PII are blurred. In total, 612 hours of the EGO4D dataset contains video where participants consented to remain unblurred.  Please reference \u201cEgo4D: Around the World in 3,000 Hours of Egocentric Video\u201d for detailed information about our de-identification process, standards, and collection efforts. Should any researcher, participant or data user encounter clips they have been insufficiently redacted, or for any other privacy concerns, please contact us immediately at privacy@ego4d-data.org.","sidebar":"tutorialSidebar"},"start-here":{"id":"start-here","title":"Start Here","description":"The Ego4D v2.0 update is now publicly available.","sidebar":"tutorialSidebar"},"updates":{"id":"updates","title":"Updates","description":"Ego4D was recently updated to version v2.0 (Feb \'23) - focused on additional Forecasting, Hands & Objects (243 hrs vs 120 hrs) and Natural Language Queries (27k vs 17.3k queries) annotations, a number of corrections and usability enhancements, and two new related dataset enhancements (PACO object and EgoTracks tracking path annotations).  Details below.","sidebar":"tutorialSidebar"},"viz":{"id":"viz","title":"Visualization Tool","description":"The dataset visualization tool is publicly available at//visualize.ego4d-data.org. You will need an approved license for access.","sidebar":"tutorialSidebar"}}}')}}]);