"use strict";(self.webpackChunkdocs=self.webpackChunkdocs||[]).push([[376],{3905:(e,t,a)=>{a.d(t,{Zo:()=>p,kt:()=>f});var n=a(7294);function r(e,t,a){return t in e?Object.defineProperty(e,t,{value:a,enumerable:!0,configurable:!0,writable:!0}):e[t]=a,e}function o(e,t){var a=Object.keys(e);if(Object.getOwnPropertySymbols){var n=Object.getOwnPropertySymbols(e);t&&(n=n.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),a.push.apply(a,n)}return a}function i(e){for(var t=1;t<arguments.length;t++){var a=null!=arguments[t]?arguments[t]:{};t%2?o(Object(a),!0).forEach((function(t){r(e,t,a[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(a)):o(Object(a)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(a,t))}))}return e}function l(e,t){if(null==e)return{};var a,n,r=function(e,t){if(null==e)return{};var a,n,r={},o=Object.keys(e);for(n=0;n<o.length;n++)a=o[n],t.indexOf(a)>=0||(r[a]=e[a]);return r}(e,t);if(Object.getOwnPropertySymbols){var o=Object.getOwnPropertySymbols(e);for(n=0;n<o.length;n++)a=o[n],t.indexOf(a)>=0||Object.prototype.propertyIsEnumerable.call(e,a)&&(r[a]=e[a])}return r}var s=n.createContext({}),d=function(e){var t=n.useContext(s),a=t;return e&&(a="function"==typeof e?e(t):i(i({},t),e)),a},p=function(e){var t=d(e.components);return n.createElement(s.Provider,{value:t},e.children)},c="mdxType",m={inlineCode:"code",wrapper:function(e){var t=e.children;return n.createElement(n.Fragment,{},t)}},u=n.forwardRef((function(e,t){var a=e.components,r=e.mdxType,o=e.originalType,s=e.parentName,p=l(e,["components","mdxType","originalType","parentName"]),c=d(a),u=r,f=c["".concat(s,".").concat(u)]||c[u]||m[u]||o;return a?n.createElement(f,i(i({ref:t},p),{},{components:a})):n.createElement(f,i({ref:t},p))}));function f(e,t){var a=arguments,r=t&&t.mdxType;if("string"==typeof e||r){var o=a.length,i=new Array(o);i[0]=u;var l={};for(var s in t)hasOwnProperty.call(t,s)&&(l[s]=t[s]);l.originalType=e,l[c]="string"==typeof e?e:r,i[1]=l;for(var d=2;d<o;d++)i[d]=a[d];return n.createElement.apply(null,i)}return n.createElement.apply(null,a)}u.displayName="MDXCreateElement"},6733:(e,t,a)=>{a.r(t),a.d(t,{assets:()=>s,contentTitle:()=>i,default:()=>m,frontMatter:()=>o,metadata:()=>l,toc:()=>d});var n=a(7462),r=(a(7294),a(3905));const o={sidebar_position:5},i="Gaze",l={unversionedId:"data/gaze",id:"data/gaze",title:"Gaze",description:"Gaze is available in two forms:",source:"@site/docs/data/gaze.md",sourceDirName:"data",slug:"/data/gaze",permalink:"/docs/data/gaze",draft:!1,tags:[],version:"current",sidebarPosition:5,frontMatter:{sidebar_position:5},sidebar:"tutorialSidebar",previous:{title:"Videos",permalink:"/docs/data/videos"},next:{title:"IMU",permalink:"/docs/data/imu"}},s={},d=[{value:"Download",id:"download",level:2},{value:"Sample",id:"sample",level:2},{value:"Notes",id:"notes",level:2},{value:"EGTEA Gaze+",id:"egtea-gaze",level:2}],p={toc:d},c="wrapper";function m(e){let{components:t,...a}=e;return(0,r.kt)(c,(0,n.Z)({},p,a,{components:t,mdxType:"MDXLayout"}),(0,r.kt)("h1",{id:"gaze"},"Gaze"),(0,r.kt)("p",null,"Gaze is available in two forms:"),(0,r.kt)("ol",null,(0,r.kt)("li",{parentName:"ol"},"Similar to ",(0,r.kt)("a",{parentName:"li",href:"/docs/data/imu"},"IMU"),", gaze is available in a flat CSV file\nfor a subset of ",(0,r.kt)("a",{parentName:"li",href:"/docs/data/videos"},"videos"),'. These files are processed from\nthe original CSV files (please see "Notes" below as for why)'),(0,r.kt)("li",{parentName:"ol"},"Burned in gaze videos. These videos have an overlay of the camera wearer's gaze as a 2D point graphic.")),(0,r.kt)("p",null,"Unprocessed gaze data is available (directly from the consortium). Please refer to ",(0,r.kt)("a",{parentName:"p",href:"/docs/data/unprocessed_data"},"unprocessed data")," for details on downloading burned-in gaze videos."),(0,r.kt)("p",null,"We refer to a recent paper for data split (insert this link: ",(0,r.kt)("a",{parentName:"p",href:"https://github.com/BolinLai/GLC/blob/main/slowfast/datasets/DATASET.md"},"https://github.com/BolinLai/GLC/blob/main/slowfast/datasets/DATASET.md"),") and preprocessing scripts on egocentric gaze estimation task."),(0,r.kt)("h2",{id:"download"},"Download"),(0,r.kt)("p",null,"You can download the gaze data with the CLI using ",(0,r.kt)("inlineCode",{parentName:"p"},"--datasets gaze"),"."),(0,r.kt)("h2",{id:"sample"},"Sample"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre"},"component_idx,component_timestamp_s,canonical_timestamp_s,world_index,confidence,norm_pos_x,norm_pos_y,base_data,gaze_point_3d_x,gaze_point_3d_y,gaze_point_3d_z,eye_center0_3d_x,eye_center0_3d_y,eye_center0_3d_z,gaze_normal0_x,gaze_normal0_y,gaze_normal0_z,eye_center1_3d_x,eye_center1_3d_y,eye_center1_3d_z,gaze_normal1_x,gaze_normal1_y,gaze_normal1_z\n0,0.0,0.0,10583.0,1.0,0.4422956915462719,0.440328527379919,,,,,,,,,,,,,,,,\n0,0.004056999999988875,0.004056999999988875,10583.0,1.0,0.4444741922266343,0.4417514942310474,,,,,,,,,,,,,,,,\n0,0.008062999999992826,0.008062999999992826,10583.0,1.0,0.4420773281770594,0.4421598646375868,,,,,,,,,,,,,,,,\n0,0.016042000000084045,0.016042000000084045,10583.0,1.0,0.44133738910450654,0.442092443395544,,,,,,,,,,,,,,,,\n0,0.020003000000087923,0.020003000000087923,10583.0,1.0,0.4456248844371121,0.4425749602141204,,,,,,,,,,,,,,,,\n0,0.024024999999994634,0.024024999999994634,10583.0,1.0,0.44868000815896425,0.439816227665654,,,,,,,,,,,,,,,,\n0,0.0280380000000946,0.0280380000000946,10584.0,1.0,0.4489469528198242,0.4418025264033565,,,,,,,,,,,,,,,,\n0,0.03603500000008353,0.03603500000008353,10584.0,1.0,0.4523132829105153,0.4371138396086516,,,,,,,,,,,,,,,,\n0,0.040044000000079905,0.040044000000079905,10584.0,1.0,0.4501118098988253,0.4375872011537905,,,,,,,,,,,,,,,,\n")),(0,r.kt)("h2",{id:"notes"},"Notes"),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},"Unprocessed data has the first row set to some value ",(0,r.kt)("inlineCode",{parentName:"li"},"t>0"),". The reason for this is due to:",(0,r.kt)("ul",{parentName:"li"},(0,r.kt)("li",{parentName:"ul"},'Footage of the video was trimmed and aligned to the gaze\ndata. The corresponding Gaze CSV was trimmed by taking a range\nof the rows, leaving the "raw" data in-tact but not having the\ntimestamps adjusted.'),(0,r.kt)("li",{parentName:"ul"},"Processed data corrects this by offsetting each time-stamp, assuming\nthe first row is associated to ",(0,r.kt)("inlineCode",{parentName:"li"},"t=0"),"."))),(0,r.kt)("li",{parentName:"ul"},"Data is recorded at a higher frequency than the frame rate of the video"),(0,r.kt)("li",{parentName:"ul"},"As of writing, the only fields populated in each CSV are ",(0,r.kt)("inlineCode",{parentName:"li"},'"world_index"'),", ",(0,r.kt)("inlineCode",{parentName:"li"},'"confidence"'),", ",(0,r.kt)("inlineCode",{parentName:"li"},'"norm_pos_x"')," and ",(0,r.kt)("inlineCode",{parentName:"li"},'"norm_pos_y"')),(0,r.kt)("li",{parentName:"ul"},"Every video with gaze has only one video component, with relatively normal properties; such as, the video stream always starts at ",(0,r.kt)("inlineCode",{parentName:"li"},"t=0"),", etc.")),(0,r.kt)("h2",{id:"egtea-gaze"},"EGTEA Gaze+"),(0,r.kt)("p",null,"For the EGTEA Gaze+ dataset, we refer to a ",(0,r.kt)("a",{parentName:"p",href:"https://github.com/BolinLai/GLC/blob/main/slowfast/datasets/DATASET.md"},"recent paper")," for data splits and preprocessing scripts on the egocentric gaze estimation task."))}m.isMDXComponent=!0}}]);