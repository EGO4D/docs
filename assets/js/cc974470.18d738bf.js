"use strict";(self.webpackChunkdocs=self.webpackChunkdocs||[]).push([[484],{3905:function(e,t,a){a.d(t,{Zo:function(){return p},kt:function(){return c}});var n=a(7294);function r(e,t,a){return t in e?Object.defineProperty(e,t,{value:a,enumerable:!0,configurable:!0,writable:!0}):e[t]=a,e}function o(e,t){var a=Object.keys(e);if(Object.getOwnPropertySymbols){var n=Object.getOwnPropertySymbols(e);t&&(n=n.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),a.push.apply(a,n)}return a}function i(e){for(var t=1;t<arguments.length;t++){var a=null!=arguments[t]?arguments[t]:{};t%2?o(Object(a),!0).forEach((function(t){r(e,t,a[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(a)):o(Object(a)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(a,t))}))}return e}function l(e,t){if(null==e)return{};var a,n,r=function(e,t){if(null==e)return{};var a,n,r={},o=Object.keys(e);for(n=0;n<o.length;n++)a=o[n],t.indexOf(a)>=0||(r[a]=e[a]);return r}(e,t);if(Object.getOwnPropertySymbols){var o=Object.getOwnPropertySymbols(e);for(n=0;n<o.length;n++)a=o[n],t.indexOf(a)>=0||Object.prototype.propertyIsEnumerable.call(e,a)&&(r[a]=e[a])}return r}var d=n.createContext({}),s=function(e){var t=n.useContext(d),a=t;return e&&(a="function"==typeof e?e(t):i(i({},t),e)),a},p=function(e){var t=s(e.components);return n.createElement(d.Provider,{value:t},e.children)},m={inlineCode:"code",wrapper:function(e){var t=e.children;return n.createElement(n.Fragment,{},t)}},u=n.forwardRef((function(e,t){var a=e.components,r=e.mdxType,o=e.originalType,d=e.parentName,p=l(e,["components","mdxType","originalType","parentName"]),u=s(a),c=r,h=u["".concat(d,".").concat(c)]||u[c]||m[c]||o;return a?n.createElement(h,i(i({ref:t},p),{},{components:a})):n.createElement(h,i({ref:t},p))}));function c(e,t){var a=arguments,r=t&&t.mdxType;if("string"==typeof e||r){var o=a.length,i=new Array(o);i[0]=u;var l={};for(var d in t)hasOwnProperty.call(t,d)&&(l[d]=t[d]);l.originalType=e,l.mdxType="string"==typeof e?e:r,i[1]=l;for(var s=2;s<o;s++)i[s]=a[s];return n.createElement.apply(null,i)}return n.createElement.apply(null,a)}u.displayName="MDXCreateElement"},2062:function(e,t,a){a.r(t),a.d(t,{frontMatter:function(){return l},contentTitle:function(){return d},metadata:function(){return s},toc:function(){return p},default:function(){return u}});var n=a(7462),r=a(3366),o=(a(7294),a(3905)),i=["components"],l={sidebar_position:7},d="Features",s={unversionedId:"data/features",id:"data/features",isDocsHomePage:!1,title:"Features",description:"The features have been updated as of 2022-06-07. Please re-download them if you",source:"@site/docs/data/features.md",sourceDirName:"data",slug:"/data/features",permalink:"/docs/data/features",tags:[],version:"current",sidebarPosition:7,frontMatter:{sidebar_position:7},sidebar:"tutorialSidebar",previous:{title:"IMU",permalink:"/docs/data/imu"},next:{title:"Annotation Schemas",permalink:"/docs/data/annotations-schemas"}},p=[{value:"Want to Add a Model?",id:"want-to-add-a-model",children:[],level:2},{value:"Description",id:"description",children:[],level:2},{value:"Example Window Stride",id:"example-window-stride",children:[],level:2},{value:"Implementation",id:"implementation",children:[],level:2}],m={toc:p};function u(e){var t=e.components,a=(0,r.Z)(e,i);return(0,o.kt)("wrapper",(0,n.Z)({},m,a,{components:t,mdxType:"MDXLayout"}),(0,o.kt)("h1",{id:"features"},"Features"),(0,o.kt)("div",{className:"admonition admonition-note alert alert--secondary"},(0,o.kt)("div",{parentName:"div",className:"admonition-heading"},(0,o.kt)("h5",{parentName:"div"},(0,o.kt)("span",{parentName:"h5",className:"admonition-icon"},(0,o.kt)("svg",{parentName:"span",xmlns:"http://www.w3.org/2000/svg",width:"14",height:"16",viewBox:"0 0 14 16"},(0,o.kt)("path",{parentName:"svg",fillRule:"evenodd",d:"M6.3 5.69a.942.942 0 0 1-.28-.7c0-.28.09-.52.28-.7.19-.18.42-.28.7-.28.28 0 .52.09.7.28.18.19.28.42.28.7 0 .28-.09.52-.28.7a1 1 0 0 1-.7.3c-.28 0-.52-.11-.7-.3zM8 7.99c-.02-.25-.11-.48-.31-.69-.2-.19-.42-.3-.69-.31H6c-.27.02-.48.13-.69.31-.2.2-.3.44-.31.69h1v3c.02.27.11.5.31.69.2.2.42.31.69.31h1c.27 0 .48-.11.69-.31.2-.19.3-.42.31-.69H8V7.98v.01zM7 2.3c-3.14 0-5.7 2.54-5.7 5.68 0 3.14 2.56 5.7 5.7 5.7s5.7-2.55 5.7-5.7c0-3.15-2.56-5.69-5.7-5.69v.01zM7 .98c3.86 0 7 3.14 7 7s-3.14 7-7 7-7-3.12-7-7 3.14-7 7-7z"}))),"Features extraction bug")),(0,o.kt)("div",{parentName:"div",className:"admonition-content"},(0,o.kt)("p",{parentName:"div"},"The features have been updated as of 2022-06-07. Please re-download them if you\nhave used them before this date. There was a bug in the feature generation\npipeline which had caused the model to not be fed the video input correctly. You\ncan find the paths to the old features by reading the description below."))),(0,o.kt)("p",null,"Pre-extracted feature vectors are available for every video in the\ndataset. They can be accessed with the ",(0,o.kt)("strong",{parentName:"p"},(0,o.kt)("a",{parentName:"strong",href:"https://github.com/facebookresearch/Ego4d/blob/main/ego4d/cli/README.md"},"EGO4D\nCLI")),". Please consult the table below for the appropriate ",(0,o.kt)("inlineCode",{parentName:"p"},"--dataset")," option."),(0,o.kt)("h2",{id:"want-to-add-a-model"},"Want to Add a Model?"),(0,o.kt)("p",null,"Refer to the features ",(0,o.kt)("a",{parentName:"p",href:"https://github.com/facebookresearch/Ego4d/tree/main/ego4d/features"},"README on the Ego4D\ngithub"),"."),(0,o.kt)("p",null,"If you need support in running the job to extract features, please open an issue\non the github repository."),(0,o.kt)("h2",{id:"description"},"Description"),(0,o.kt)("p",null,"Here is a table of the features pre-extracted from Ego4D. These\nfeatures are extracted from the canonical videos. Canonical videos are\nall 30FPS."),(0,o.kt)("p",null,"Window Size and Stride are in frames."),(0,o.kt)("table",null,(0,o.kt)("thead",{parentName:"table"},(0,o.kt)("tr",{parentName:"thead"},(0,o.kt)("th",{parentName:"tr",align:null},"Feature Type"),(0,o.kt)("th",{parentName:"tr",align:null},"Dataset(s) Trained On"),(0,o.kt)("th",{parentName:"tr",align:null},"Model Arch"),(0,o.kt)("th",{parentName:"tr",align:null},"Window Size"),(0,o.kt)("th",{parentName:"tr",align:null},"Stride"),(0,o.kt)("th",{parentName:"tr",align:null},"Model Weights Location"),(0,o.kt)("th",{parentName:"tr",align:null},"Notes"))),(0,o.kt)("tbody",{parentName:"table"},(0,o.kt)("tr",{parentName:"tbody"},(0,o.kt)("td",{parentName:"tr",align:null},(0,o.kt)("inlineCode",{parentName:"td"},"slowfast8x8_r101_k400")),(0,o.kt)("td",{parentName:"tr",align:null},"Kinetics 400"),(0,o.kt)("td",{parentName:"tr",align:null},"SlowFast 8x8 (R101 backbone)"),(0,o.kt)("td",{parentName:"tr",align:null},"32"),(0,o.kt)("td",{parentName:"tr",align:null},"16"),(0,o.kt)("td",{parentName:"tr",align:null},"torchub path: facebookresearch/pytorchvideo/slowfast_r101"),(0,o.kt)("td",{parentName:"tr",align:null})),(0,o.kt)("tr",{parentName:"tbody"},(0,o.kt)("td",{parentName:"tr",align:null},(0,o.kt)("inlineCode",{parentName:"td"},"omnivore_video_swinl")),(0,o.kt)("td",{parentName:"tr",align:null},"Kinetics 400 / ImageNet-1K"),(0,o.kt)("td",{parentName:"tr",align:null},"Omnivore (swin L); video head"),(0,o.kt)("td",{parentName:"tr",align:null},"32"),(0,o.kt)("td",{parentName:"tr",align:null},"16"),(0,o.kt)("td",{parentName:"tr",align:null},(0,o.kt)("a",{parentName:"td",href:"https://github.com/facebookresearch/omnivore#model-zoo"},"https://github.com/facebookresearch/omnivore#model-zoo")),(0,o.kt)("td",{parentName:"tr",align:null})),(0,o.kt)("tr",{parentName:"tbody"},(0,o.kt)("td",{parentName:"tr",align:null},(0,o.kt)("inlineCode",{parentName:"td"},"omnivore_image_swinl")),(0,o.kt)("td",{parentName:"tr",align:null},"Kinetics 400 / ImageNet-1K"),(0,o.kt)("td",{parentName:"tr",align:null},"Omnivore (swin L); image head"),(0,o.kt)("td",{parentName:"tr",align:null},"1"),(0,o.kt)("td",{parentName:"tr",align:null},"5"),(0,o.kt)("td",{parentName:"tr",align:null},(0,o.kt)("a",{parentName:"td",href:"https://github.com/facebookresearch/omnivore#model-zoo"},"https://github.com/facebookresearch/omnivore#model-zoo")),(0,o.kt)("td",{parentName:"tr",align:null})),(0,o.kt)("tr",{parentName:"tbody"},(0,o.kt)("td",{parentName:"tr",align:null},(0,o.kt)("inlineCode",{parentName:"td"},"omnivore_video_swinl_fp16")),(0,o.kt)("td",{parentName:"tr",align:null},"Kinetics 400 / ImageNet-1K"),(0,o.kt)("td",{parentName:"tr",align:null},"Omnivore (swin L); video head"),(0,o.kt)("td",{parentName:"tr",align:null},"32"),(0,o.kt)("td",{parentName:"tr",align:null},"16"),(0,o.kt)("td",{parentName:"tr",align:null},(0,o.kt)("a",{parentName:"td",href:"https://github.com/facebookresearch/omnivore#model-zoo"},"https://github.com/facebookresearch/omnivore#model-zoo")),(0,o.kt)("td",{parentName:"tr",align:null},"FP16 variant of ",(0,o.kt)("inlineCode",{parentName:"td"},"omnivore_video_swinl"))))),(0,o.kt)("p",null,"There is additionally ",(0,o.kt)("inlineCode",{parentName:"p"},"slowfast8x8_r101_k400_deprecated")," and ",(0,o.kt)("inlineCode",{parentName:"p"},"omnivore_video_deprecated")," for the features released before 2022-06-07"),(0,o.kt)("p",null,"Features are extracted in a moving window fashion. At every extraction\npoint the model sees the next Window Size (",(0,o.kt)("inlineCode",{parentName:"p"},"W"),") frames (i.e. at frame\n",(0,o.kt)("inlineCode",{parentName:"p"},"i")," the model sees features ",(0,o.kt)("inlineCode",{parentName:"p"},"[i, i + W)")," frames). The window starts at\nframe 0, and then is offset by the stride until the end of the video\nis reached."),(0,o.kt)("p",null,"There is a boundary condition where the last window may extend past\nthe video. In this case, the extraction point is backed up such that a\nwindow with ",(0,o.kt)("inlineCode",{parentName:"p"},"W")," frames from the video is used. This occurs when the\nnumber of frames in the canonical video is not divisible by the stride."),(0,o.kt)("h2",{id:"example-window-stride"},"Example Window Stride"),(0,o.kt)("p",null,"Let's say a video has 39 frames. The frames for extraction will be (in frame numbers):"),(0,o.kt)("ul",null,(0,o.kt)("li",{parentName:"ul"},"[0, 31]"),(0,o.kt)("li",{parentName:"ul"},"[7, 38]"," which is \u201cback-padded\u201d from ","[16, 47]"," to fit the last window")),(0,o.kt)("h2",{id:"implementation"},"Implementation"),(0,o.kt)("ul",null,(0,o.kt)("li",{parentName:"ul"},"Read the ",(0,o.kt)("a",{parentName:"li",href:"https://github.com/facebookresearch/Ego4d/tree/main/ego4d/features"},"README on the Ego4D github")," to run or use the code yourself"),(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("a",{parentName:"li",href:"https://pytorchvideo.readthedocs.io/en/latest/api/data/data.html?highlight=ClipSampler#pytorchvideo.data.UniformClipSampler"},"UniformClipSampler")," from PytorchVideo is used")))}u.isMDXComponent=!0}}]);