"use strict";(self.webpackChunkdocs=self.webpackChunkdocs||[]).push([[736],{3905:(e,t,a)=>{a.d(t,{Zo:()=>d,kt:()=>u});var n=a(7294);function i(e,t,a){return t in e?Object.defineProperty(e,t,{value:a,enumerable:!0,configurable:!0,writable:!0}):e[t]=a,e}function o(e,t){var a=Object.keys(e);if(Object.getOwnPropertySymbols){var n=Object.getOwnPropertySymbols(e);t&&(n=n.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),a.push.apply(a,n)}return a}function r(e){for(var t=1;t<arguments.length;t++){var a=null!=arguments[t]?arguments[t]:{};t%2?o(Object(a),!0).forEach((function(t){i(e,t,a[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(a)):o(Object(a)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(a,t))}))}return e}function s(e,t){if(null==e)return{};var a,n,i=function(e,t){if(null==e)return{};var a,n,i={},o=Object.keys(e);for(n=0;n<o.length;n++)a=o[n],t.indexOf(a)>=0||(i[a]=e[a]);return i}(e,t);if(Object.getOwnPropertySymbols){var o=Object.getOwnPropertySymbols(e);for(n=0;n<o.length;n++)a=o[n],t.indexOf(a)>=0||Object.prototype.propertyIsEnumerable.call(e,a)&&(i[a]=e[a])}return i}var l=n.createContext({}),c=function(e){var t=n.useContext(l),a=t;return e&&(a="function"==typeof e?e(t):r(r({},t),e)),a},d=function(e){var t=c(e.components);return n.createElement(l.Provider,{value:t},e.children)},p="mdxType",m={inlineCode:"code",wrapper:function(e){var t=e.children;return n.createElement(n.Fragment,{},t)}},h=n.forwardRef((function(e,t){var a=e.components,i=e.mdxType,o=e.originalType,l=e.parentName,d=s(e,["components","mdxType","originalType","parentName"]),p=c(a),h=i,u=p["".concat(l,".").concat(h)]||p[h]||m[h]||o;return a?n.createElement(u,r(r({ref:t},d),{},{components:a})):n.createElement(u,r({ref:t},d))}));function u(e,t){var a=arguments,i=t&&t.mdxType;if("string"==typeof e||i){var o=a.length,r=new Array(o);r[0]=h;var s={};for(var l in t)hasOwnProperty.call(t,l)&&(s[l]=t[l]);s.originalType=e,s[p]="string"==typeof e?e:i,r[1]=s;for(var c=2;c<o;c++)r[c]=a[c];return n.createElement.apply(null,r)}return n.createElement.apply(null,a)}h.displayName="MDXCreateElement"},3273:(e,t,a)=>{a.r(t),a.d(t,{assets:()=>l,contentTitle:()=>r,default:()=>m,frontMatter:()=>o,metadata:()=>s,toc:()=>c});var n=a(7462),i=(a(7294),a(3905));const o={sidebar_position:3},r="Videos",s={unversionedId:"data/videos",id:"data/videos",title:"Videos",description:"Videos are sourced from a variety of devices, locations and participants across a wide range of",source:"@site/docs/data/videos.md",sourceDirName:"data",slug:"/data/videos",permalink:"/docs/data/videos",draft:!1,tags:[],version:"current",sidebarPosition:3,frontMatter:{sidebar_position:3},sidebar:"tutorialSidebar",previous:{title:"Metadata",permalink:"/docs/data/metadata"},next:{title:"Gaze",permalink:"/docs/data/gaze"}},l={},c=[{value:"Background",id:"background",level:2},{value:"Non-Obvious Properties",id:"non-obvious-properties",level:3},{value:"Canonical Videos",id:"canonical-videos",level:2},{value:"How They Are Constructed",id:"how-they-are-constructed",level:3},{value:"Canonical Clips",id:"canonical-clips",level:2},{value:"Using the Annotations with Canonical Clips",id:"using-the-annotations-with-canonical-clips",level:3},{value:"Obtaining the Clips",id:"obtaining-the-clips",level:3},{value:"Canonical Clip Definitions",id:"canonical-clip-definitions",level:3},{value:"Forecasting Hands and Objects (FHO)",id:"forecasting-hands-and-objects-fho",level:4},{value:"Episodic-Memory (NLQ, VQ, MQ)",id:"episodic-memory-nlq-vq-mq",level:4},{value:"AV",id:"av",level:4},{value:"Video Components",id:"video-components",level:2},{value:"Attributes of the Data",id:"attributes-of-the-data",level:3},{value:"Inconsistent Properties",id:"inconsistent-properties",level:4}],d={toc:c},p="wrapper";function m(e){let{components:t,...a}=e;return(0,i.kt)(p,(0,n.Z)({},d,a,{components:t,mdxType:"MDXLayout"}),(0,i.kt)("h1",{id:"videos"},"Videos"),(0,i.kt)("p",null,"Videos are sourced from a variety of devices, locations and participants across a wide range of\nscenarios.  The original source videos (",(0,i.kt)("strong",{parentName:"p"},"video components"),") that were captured by university participants were composed into standardized, full length videos (",(0,i.kt)("strong",{parentName:"p"},"canonical videos"),", the primary videos in the dataset).  Shorter clips of the longer videos were then annotated to generate the dataset annotations, and finally shorter ",(0,i.kt)("strong",{parentName:"p"},"canonical clips")," were formed from the videos and exported with the dataset."),(0,i.kt)("p",null,"Accordingly, video data is available in three forms for the dataset. Each form can be identified with a unique identifier string (uuid4):"),(0,i.kt)("ol",null,(0,i.kt)("li",{parentName:"ol"},(0,i.kt)("strong",{parentName:"li"},"Canonical videos")," - Derived from the video components"),(0,i.kt)("li",{parentName:"ol"},(0,i.kt)("strong",{parentName:"li"},"Canonical Clips")," - Clips associated to specific ",(0,i.kt)("a",{parentName:"li",href:"/docs/data/annotations-schemas"},"annotation")," data and derived from the canonical videos."),(0,i.kt)("li",{parentName:"ol"},"Video Components - The raw components used to construct the videos and primary provided as an ancillarly export for thoroughness.")),(0,i.kt)("p",null,"The canonical videos or the canonical clips are the ",(0,i.kt)("strong",{parentName:"p"},"recomended")," way to use the dataset."),(0,i.kt)("h2",{id:"background"},"Background"),(0,i.kt)("p",null,"Each video, in the dataset, is in a video container (such as mp4, webm, etc.)\nand may have multiple streams. In other words, for a video we have the\nfollowing:"),(0,i.kt)("ol",null,(0,i.kt)("li",{parentName:"ol"},"The container"),(0,i.kt)("li",{parentName:"ol"},"Video stream"),(0,i.kt)("li",{parentName:"ol"},"Audio stream")),(0,i.kt)("h3",{id:"non-obvious-properties"},"Non-Obvious Properties"),(0,i.kt)("p",null,"It is possible for the following properties to be true:"),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},"The container ends ",(0,i.kt)("strong",{parentName:"li"},"before")," or ",(0,i.kt)("strong",{parentName:"li"},"after")," one or both of the stream\nends. In the case that the:",(0,i.kt)("ul",{parentName:"li"},(0,i.kt)("li",{parentName:"ul"},"Video stream ends before: blank frames are played"),(0,i.kt)("li",{parentName:"ul"},"Video stream ends after: video players will continue to play the stream"))),(0,i.kt)("li",{parentName:"ul"},"The audio stream starts after the video stream starts"),(0,i.kt)("li",{parentName:"ul"},"The video stream starts after the audio stream starts")),(0,i.kt)("p",null,"To be clear, in instances where raw components is contained within the\nvideo container (by multiple frames), it has no frame data in these\nregions."),(0,i.kt)("p",null,"These properties can be fixed by either:"),(0,i.kt)("ol",null,(0,i.kt)("li",{parentName:"ol"},"Remuxing the video file to another MP4 container, i.e. ",(0,i.kt)("inlineCode",{parentName:"li"},"ffmpeg -i in.mp4 -c copy out.mp4")),(0,i.kt)("li",{parentName:"ol"},"Compressing the video file")),(0,i.kt)("h2",{id:"canonical-videos"},"Canonical Videos"),(0,i.kt)("p",null,"The purpose of the canonical videos is to normalize the videos in\norder to simplify the usage of the dataset, and are the primary way we expect\nusers to consume the dataset."),(0,i.kt)("p",null,"Canonical videos are normalized videos constructed from the ",(0,i.kt)("a",{parentName:"p",href:"#video-components"},"video\ncomponents"),", concatenated together with the following\ncharacteristics:"),(0,i.kt)("ol",null,(0,i.kt)("li",{parentName:"ol"},"30FPS"),(0,i.kt)("li",{parentName:"ol"},"Sample Aspect Ratio (SAR) set to 1:1"),(0,i.kt)("li",{parentName:"ol"},"Audio set to AAC")),(0,i.kt)("p",null,"Each canonical video is:"),(0,i.kt)("ol",null,(0,i.kt)("li",{parentName:"ol"},"Compressed with a two-pass VP9 (CRF of 41)"),(0,i.kt)("li",{parentName:"ol"},"Components have their video streams trimmed. This means that:",(0,i.kt)("ol",{parentName:"li"},(0,i.kt)("li",{parentName:"ol"},"Canonical videos are a continious stream of video frames,\ni.e. if a video component starts at ",(0,i.kt)("inlineCode",{parentName:"li"},"t > 0")," the initial part of\nthe video component is removed."),(0,i.kt)("li",{parentName:"ol"},"If the audio exceeds the video stream, the audio is trimmed")))),(0,i.kt)("p",null,"FFMPEG is used for all processing."),(0,i.kt)("h3",{id:"how-they-are-constructed"},"How They Are Constructed"),(0,i.kt)("p",null,"Each video component is first compressed with a video filter to\nnormalize all properties outside of audio. During compression, videos\nare seeked to ",(0,i.kt)("inlineCode",{parentName:"p"},"vs")," where ",(0,i.kt)("inlineCode",{parentName:"p"},"vs")," is the start time of the video stream,\nsuch that components can be trimmed to the video stream."),(0,i.kt)("p",null,"After each component for a video has been compressed, they run through\nthe following steps:"),(0,i.kt)("ol",null,(0,i.kt)("li",{parentName:"ol"},"A remux of the container is performed to encode the audio to AAC or\nnormalize inconsistent audio rates"),(0,i.kt)("li",{parentName:"ol"},"FFMPEG concat demuxer is used to combine the components together\ninto one video file (with ",(0,i.kt)("a",{parentName:"li",href:"https://ffmpeg.org/ffmpeg-formats.html#Options"},(0,i.kt)("inlineCode",{parentName:"a"},"-segment_time_metadata 1")),")")),(0,i.kt)("h2",{id:"canonical-clips"},"Canonical Clips"),(0,i.kt)("p",null,"Canonical clips are trimmed videos, produced for each benchmark. They are produced by trimming/processing the canonical videos. The purpose and aim of the canonical clips is to make training on each benchmark more accessible than the full canonical video. As with the full scale videos, there are two variants of the canonical clips: clips and clips_540ss. 540ss indicates these clips are downscaled to have their shortest side 540 pixels wide or high."),(0,i.kt)("p",null,"To be clear, since the canonical clips are based off the canonical videos. They are at a constant frame rate of 30FPS. "),(0,i.kt)("p",null,"If you have feedback on how these clips are generated, please post to the forum."),(0,i.kt)("p",null,"Each clip is constructed with PyAV with the following compression parameters:"),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},"Codec: VP9"),(0,i.kt)("li",{parentName:"ul"},"Crf: 18"),(0,i.kt)("li",{parentName:"ul"},"Pixel Format: match original"),(0,i.kt)("li",{parentName:"ul"},"Constant FPS: 30"),(0,i.kt)("li",{parentName:"ul"},"Range: ",(0,i.kt)("inlineCode",{parentName:"li"},"[start_frame, end_frame)"),(0,i.kt)("ul",{parentName:"li"},(0,i.kt)("li",{parentName:"ul"},"Note: the end frame is not included in the clip")))),(0,i.kt)("h3",{id:"using-the-annotations-with-canonical-clips"},"Using the Annotations with Canonical Clips"),(0,i.kt)("p",null,'Each annotation file has their fields prefixed with "',(0,i.kt)("inlineCode",{parentName:"p"},"clip_"),'" if it is referring to a canonical clip time/frame or "',(0,i.kt)("inlineCode",{parentName:"p"},"video_"),'" if it is referring to the canonical video time/frame.'),(0,i.kt)("h3",{id:"obtaining-the-clips"},"Obtaining the Clips"),(0,i.kt)("p",null,"You can download the canonical clips with the CLI via:"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-bash"},'ego4d --output_directory="~/ego4d_data" --datasets clips \n')),(0,i.kt)("p",null,"This will download all clips for each benchmark. Provide the ",(0,i.kt)("inlineCode",{parentName:"p"},"--benchmarks")," filter if you want to filter via a specific benchmark (av, fho, em, nlq, vq, mq). Provide clips_540ss instead if you want the downscaled clips to 540 pixels on the shorter side."),(0,i.kt)("h3",{id:"canonical-clip-definitions"},"Canonical Clip Definitions"),(0,i.kt)("h4",{id:"forecasting-hands-and-objects-fho"},"Forecasting Hands and Objects (FHO)"),(0,i.kt)("p",null,"FHO's train/val/test split is partitioned by 5 minute clips, each containing a sequence of narrations and consequently hand/object interactions. The canonical clips correspond to these 5 minute intervals with an 8 second padding before and after the clip (or no padding on either end if the clip is at the beginning or end). This padding was performed to allow for context to be potentially used at training or inference time for the first or last set of annotations within the 5 minute interval. "),(0,i.kt)("h4",{id:"episodic-memory-nlq-vq-mq"},"Episodic-Memory (NLQ, VQ, MQ)"),(0,i.kt)("p",null,'Each canonical clip is associated with each "clip" referenced by each JSON file. These clips were annotated by a single annotator. These are the time ranges used for trimming. Here are some basic statistics on the length of each clip:'),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},"NLQ: average length is 10 minutes, clips are at most 20 minutes long"),(0,i.kt)("li",{parentName:"ul"},"VQ: average length is 6 minutes, clips are at most 16 minutes long"),(0,i.kt)("li",{parentName:"ul"},"MQ: average length is 7.8 minutes, clips are at most 8 minutes long")),(0,i.kt)("h4",{id:"av"},"AV"),(0,i.kt)("p",null,'Canonical clips are associated with the "clips" field in the annotation JSON file. These are roughly 5 minute intervals.'),(0,i.kt)("h2",{id:"video-components"},"Video Components"),(0,i.kt)("p",null,"Majoriy of the video components in the dataset have been compressed\nand have had their metadata stripped prior to them being used. Hence\nin many cases where there was originally IMU or GPU metadata there no\nlonger is."),(0,i.kt)("p",null,"The raw video component data is available through ",(0,i.kt)("strong",{parentName:"p"},(0,i.kt)("a",{parentName:"strong",href:"https://github.com/facebookresearch/Ego4d/blob/main/ego4d/cli/README.md"},"EGO4D\nCLI")),"\nwith the ",(0,i.kt)("inlineCode",{parentName:"p"},"--raw_components")," option."),(0,i.kt)("h3",{id:"attributes-of-the-data"},"Attributes of the Data"),(0,i.kt)("h4",{id:"inconsistent-properties"},"Inconsistent Properties"),(0,i.kt)("ol",null,(0,i.kt)("li",{parentName:"ol"},"Video timebases (base numerator/denominator)"),(0,i.kt)("li",{parentName:"ol"},"Audio timebases (base numerator/denominator)"),(0,i.kt)("li",{parentName:"ol"},"FPS"),(0,i.kt)("li",{parentName:"ol"},"Audio rate (32KHz vs 48KHz)"),(0,i.kt)("li",{parentName:"ol"},"Audio channel layout (mono vs. audio)")),(0,i.kt)("p",null,"Additionally many video components have ",(0,i.kt)("a",{parentName:"p",href:"#non-obvious-properties"},"non-obvious\nproperties"),"."),(0,i.kt)("p",null,"TODO: stats"))}m.isMDXComponent=!0}}]);