"use strict";(self.webpackChunkdocs=self.webpackChunkdocs||[]).push([[900],{3905:function(e,t,n){n.d(t,{Zo:function(){return m},kt:function(){return k}});var a=n(7294);function r(e,t,n){return t in e?Object.defineProperty(e,t,{value:n,enumerable:!0,configurable:!0,writable:!0}):e[t]=n,e}function o(e,t){var n=Object.keys(e);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);t&&(a=a.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),n.push.apply(n,a)}return n}function i(e){for(var t=1;t<arguments.length;t++){var n=null!=arguments[t]?arguments[t]:{};t%2?o(Object(n),!0).forEach((function(t){r(e,t,n[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(n)):o(Object(n)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(n,t))}))}return e}function p(e,t){if(null==e)return{};var n,a,r=function(e,t){if(null==e)return{};var n,a,r={},o=Object.keys(e);for(a=0;a<o.length;a++)n=o[a],t.indexOf(n)>=0||(r[n]=e[n]);return r}(e,t);if(Object.getOwnPropertySymbols){var o=Object.getOwnPropertySymbols(e);for(a=0;a<o.length;a++)n=o[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(r[n]=e[n])}return r}var s=a.createContext({}),l=function(e){var t=a.useContext(s),n=t;return e&&(n="function"==typeof e?e(t):i(i({},t),e)),n},m=function(e){var t=l(e.components);return a.createElement(s.Provider,{value:t},e.children)},c={inlineCode:"code",wrapper:function(e){var t=e.children;return a.createElement(a.Fragment,{},t)}},d=a.forwardRef((function(e,t){var n=e.components,r=e.mdxType,o=e.originalType,s=e.parentName,m=p(e,["components","mdxType","originalType","parentName"]),d=l(n),k=r,g=d["".concat(s,".").concat(k)]||d[k]||c[k]||o;return n?a.createElement(g,i(i({ref:t},m),{},{components:n})):a.createElement(g,i({ref:t},m))}));function k(e,t){var n=arguments,r=t&&t.mdxType;if("string"==typeof e||r){var o=n.length,i=new Array(o);i[0]=d;var p={};for(var s in t)hasOwnProperty.call(t,s)&&(p[s]=t[s]);p.originalType=e,p.mdxType="string"==typeof e?e:r,i[1]=p;for(var l=2;l<o;l++)i[l]=n[l];return a.createElement.apply(null,i)}return a.createElement.apply(null,n)}d.displayName="MDXCreateElement"},2276:function(e,t,n){n.r(t),n.d(t,{frontMatter:function(){return p},contentTitle:function(){return s},metadata:function(){return l},toc:function(){return m},default:function(){return d}});var a=n(7462),r=n(3366),o=(n(7294),n(3905)),i=["components"],p={title:"Ego4D Data Overview",sidebar_position:4},s=void 0,l={unversionedId:"data-overview",id:"data-overview",isDocsHomePage:!1,title:"Ego4D Data Overview",description:"WIP: Includes internal links, broken markdown, etc to be resolved",source:"@site/docs/data-overview.md",sourceDirName:".",slug:"/data-overview",permalink:"/docs/data-overview",editUrl:"https://https://ego4d-data.org/docs/data-overview.md",tags:[],version:"current",sidebarPosition:4,frontMatter:{title:"Ego4D Data Overview",sidebar_position:4},sidebar:"tutorialSidebar",previous:{title:"Social Interactions",permalink:"/docs/benchmarks/Social"},next:{title:"Annotations",permalink:"/docs/annotations"}},m=[{value:"Background",id:"background",children:[],level:2},{value:"Key Information",id:"key-information",children:[],level:2},{value:"Annotations tl;dr",id:"annotations-tldr",children:[],level:2},{value:"Narrations",id:"narrations",children:[],level:2},{value:"Benchmark Annotations",id:"benchmark-annotations",children:[],level:2},{value:"Episodic Memory",id:"episodic-memory",children:[{value:"Natural Language Queries",id:"natural-language-queries",children:[],level:3},{value:"Moments",id:"moments",children:[],level:3},{value:"Visual Object Queries",id:"visual-object-queries",children:[],level:3}],level:2},{value:"Forecasting + Hands &amp; Objects (FHO)",id:"forecasting--hands--objects-fho",children:[{value:"Stage 1 - Critical Frames",id:"stage-1---critical-frames",children:[],level:3},{value:"Stage 2 - Pre-condition",id:"stage-2---pre-condition",children:[],level:3},{value:"Stage 3 - Post-condition",id:"stage-3---post-condition",children:[],level:3}],level:2},{value:"Audio-Visual Diarization &amp; Social (AVS)",id:"audio-visual-diarization--social-avs",children:[{value:"AV Step 0: Automated Face &amp; Head Detection",id:"av-step-0-automated-face--head-detection",children:[],level:3},{value:"AV Step 1: Face &amp; Head Tracks Correction",id:"av-step-1-face--head-tracks-correction",children:[],level:3},{value:"AV Step 2: Speaker Labeling and AV anchor extraction",id:"av-step-2-speaker-labeling-and-av-anchor-extraction",children:[],level:3},{value:"AV Step 3: Speech Segmentation (Per Speaker)",id:"av-step-3-speech-segmentation-per-speaker",children:[],level:3},{value:"AV Step 4: Transcription",id:"av-step-4-transcription",children:[],level:3},{value:"AV Step 5: Correcting Speech Transcriptions [WIP]",id:"av-step-5-correcting-speech-transcriptions-wip",children:[],level:3},{value:"Social Step 1: Camera-Wearer Attention",id:"social-step-1-camera-wearer-attention",children:[],level:3},{value:"Social Step 2: Speech Target Classification",id:"social-step-2-speech-target-classification",children:[],level:3}],level:2}],c={toc:m};function d(e){var t=e.components,p=(0,r.Z)(e,i);return(0,o.kt)("wrapper",(0,a.Z)({},c,p,{components:t,mdxType:"MDXLayout"}),(0,o.kt)("p",null,(0,o.kt)("strong",{parentName:"p"},"WIP: Includes internal links, broken markdown, etc to be resolved")),(0,o.kt)("p",null,(0,o.kt)("strong",{parentName:"p"},(0,o.kt)("a",{parentName:"strong",href:"#background"},"Background"))),(0,o.kt)("blockquote",null,(0,o.kt)("p",{parentName:"blockquote"},(0,o.kt)("a",{parentName:"p",href:"#key-information"},"Key Information")," "),(0,o.kt)("p",{parentName:"blockquote"},(0,o.kt)("a",{parentName:"p",href:"#annotations-tldr"},"Annotations tl;dr")," ")),(0,o.kt)("p",null,(0,o.kt)("strong",{parentName:"p"},(0,o.kt)("a",{parentName:"strong",href:"#pre-annotations-narrations"},"Pre-annotations: Narrations"))),(0,o.kt)("p",null,(0,o.kt)("strong",{parentName:"p"},(0,o.kt)("a",{parentName:"strong",href:"#annotations"},"Annotations"))),(0,o.kt)("blockquote",null,(0,o.kt)("p",{parentName:"blockquote"},(0,o.kt)("a",{parentName:"p",href:"#episodic-memory"},"Episodic Memory")),(0,o.kt)("p",{parentName:"blockquote"},(0,o.kt)("a",{parentName:"p",href:"#natural-language-queries"},"Natural Language Queries")),(0,o.kt)("p",{parentName:"blockquote"},(0,o.kt)("a",{parentName:"p",href:"#moments"},"Moments")),(0,o.kt)("p",{parentName:"blockquote"},(0,o.kt)("a",{parentName:"p",href:"#visual-object-queries"},"Visual Object Queries")),(0,o.kt)("p",{parentName:"blockquote"},(0,o.kt)("a",{parentName:"p",href:"#forecasting-hands-objects-fho"},"Forecasting + Hands & Objects (FHO)")),(0,o.kt)("p",{parentName:"blockquote"},(0,o.kt)("a",{parentName:"p",href:"#stage-1---critical-frames"},"Stage 1 - Critical Frames")," "),(0,o.kt)("p",{parentName:"blockquote"},(0,o.kt)("a",{parentName:"p",href:"#stage-2---pre-condition"},"Stage 2 - Pre-condition")," "),(0,o.kt)("p",{parentName:"blockquote"},(0,o.kt)("a",{parentName:"p",href:"#stage-3---post-condition"},"Stage 3 - Post-condition")," "),(0,o.kt)("p",{parentName:"blockquote"},(0,o.kt)("a",{parentName:"p",href:"#audio-visual-diarization-social-avs"},"Audio-Visual Diarization & Social (AVS)")," "),(0,o.kt)("p",{parentName:"blockquote"},(0,o.kt)("a",{parentName:"p",href:"#av-step-0-automated-face-head-detection"},"AV Step 0: Automated Face & Head Detection")," "),(0,o.kt)("p",{parentName:"blockquote"},(0,o.kt)("a",{parentName:"p",href:"#av-step-1-face-head-tracks-correction"},"AV Step 1: Face & Head Tracks Correction")," "),(0,o.kt)("p",{parentName:"blockquote"},(0,o.kt)("a",{parentName:"p",href:"#av-step-2-speaker-labeling-and-av-anchor-extraction"},"AV Step 2: Speaker Labeling and AV anchor extraction")),(0,o.kt)("p",{parentName:"blockquote"},(0,o.kt)("a",{parentName:"p",href:"#av-step-3-speech-segmentation-per-speaker"},"AV Step 3: Speech Segmentation (Per Speaker)")),(0,o.kt)("p",{parentName:"blockquote"},(0,o.kt)("a",{parentName:"p",href:"#av-step-4-transcription"},"AV Step 4: Transcription")),(0,o.kt)("p",{parentName:"blockquote"},(0,o.kt)("a",{parentName:"p",href:"#av-step-5-correcting-speech-transcriptions-wip"},"AV Step 5: Correcting Speech Transcriptions")),(0,o.kt)("p",{parentName:"blockquote"},(0,o.kt)("a",{parentName:"p",href:"#social-step-1-camera-wearer-attention"},"Social Step 1: Camera-Wearer Attention")),(0,o.kt)("p",{parentName:"blockquote"},(0,o.kt)("a",{parentName:"p",href:"#social-step-2-speech-target-classification"},"S Step 2: Speech Target Classification"))),(0,o.kt)("h2",{id:"background"},"Background"),(0,o.kt)("p",null,(0,o.kt)("strong",{parentName:"p"},"One-liner:")," Building a densely-annotated dataset of ","~","10,000 hours of\nego-centric video for public release."),(0,o.kt)("h2",{id:"key-information"},"Key Information"),(0,o.kt)("ul",null,(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("p",{parentName:"li"},"~","3,400 hours of unscripted, in-the-wild video data across:"),(0,o.kt)("blockquote",{parentName:"li"},(0,o.kt)("p",{parentName:"blockquote"},"9 countries from 13 different partner groups (+ 400 hours from Meta's reality labs).")),(0,o.kt)("blockquote",{parentName:"li"},(0,o.kt)("p",{parentName:"blockquote"},"855 unique camera-wears recording 120 different scenarios, with hundreds of different actions and objects")),(0,o.kt)("blockquote",{parentName:"li"},(0,o.kt)("p",{parentName:"blockquote"},'2.5M dense textual "narrations" (= individual text sentences describing ',"~",'2,600 hours of video data)\\"')))),(0,o.kt)("p",null,(0,o.kt)("strong",{parentName:"p"},"Devices:")),(0,o.kt)("p",null,(0,o.kt)("img",{src:n(4273).Z})),(0,o.kt)("p",null,(0,o.kt)("strong",{parentName:"p"},"Scenario breakdown:")),(0,o.kt)("p",null,(0,o.kt)("img",{src:n(6900).Z})),(0,o.kt)("h2",{id:"annotations-tldr"},"Annotations tl;dr"),(0,o.kt)("table",null,(0,o.kt)("thead",{parentName:"table"},(0,o.kt)("tr",{parentName:"thead"},(0,o.kt)("th",{parentName:"tr",align:null},(0,o.kt)("strong",{parentName:"th"},"Task")),(0,o.kt)("th",{parentName:"tr",align:null},(0,o.kt)("strong",{parentName:"th"},"Output")),(0,o.kt)("th",{parentName:"tr",align:null},(0,o.kt)("strong",{parentName:"th"},"Volume")))),(0,o.kt)("tbody",{parentName:"table"},(0,o.kt)("tr",{parentName:"tbody"},(0,o.kt)("td",{parentName:"tr",align:null},(0,o.kt)("strong",{parentName:"td"},"Pre-annotations")),(0,o.kt)("td",{parentName:"tr",align:null}),(0,o.kt)("td",{parentName:"tr",align:null})),(0,o.kt)("tr",{parentName:"tbody"},(0,o.kt)("td",{parentName:"tr",align:null},(0,o.kt)("a",{parentName:"td",href:"#pre-annotations-narrations"},"Narrations")),(0,o.kt)("td",{parentName:"tr",align:null},"Dense written sentence narrations in English & a summary of the whole video clip"),(0,o.kt)("td",{parentName:"tr",align:null},"Full Dataset")),(0,o.kt)("tr",{parentName:"tbody"},(0,o.kt)("td",{parentName:"tr",align:null},(0,o.kt)("strong",{parentName:"td"},"Episodic Memory")),(0,o.kt)("td",{parentName:"tr",align:null}),(0,o.kt)("td",{parentName:"tr",align:null})),(0,o.kt)("tr",{parentName:"tbody"},(0,o.kt)("td",{parentName:"tr",align:null},(0,o.kt)("a",{parentName:"td",href:"#natural-language-queries"},"Natural Language Queries")),(0,o.kt)("td",{parentName:"tr",align:null},"N free-form natural anguage queries per video (N=length of video in minutes) selected from a list of query templates + temporal response window from which answers can be deduced"),(0,o.kt)("td",{parentName:"tr",align:null},"~","240h")),(0,o.kt)("tr",{parentName:"tbody"},(0,o.kt)("td",{parentName:"tr",align:null},(0,o.kt)("a",{parentName:"td",href:"#moments"},"Moments")),(0,o.kt)("td",{parentName:"tr",align:null},"Temporal localizations of high level events in a long video clip from a provided taxonomy"),(0,o.kt)("td",{parentName:"tr",align:null},"~","300h")),(0,o.kt)("tr",{parentName:"tbody"},(0,o.kt)("td",{parentName:"tr",align:null},(0,o.kt)("a",{parentName:"td",href:"#visual-object-queries"},"Visual Object Queries")),(0,o.kt)("td",{parentName:"tr",align:null},"For N=3 ",(0,o.kt)("strong",{parentName:"td"},"query objects")," (freely chosen and ",(0,o.kt)("strong",{parentName:"td"},"named")," by the annotator) such that each appears at least twice at separate times in a single video, annotations include: ",(0,o.kt)("br",null)," ","(","1",")"," ",(0,o.kt)("strong",{parentName:"td"},"response track"),": bounding boxes over time for one continuous occurrence of the query object; ",(0,o.kt)("br",null)," ","(","2",")"," ",(0,o.kt)("strong",{parentName:"td"},"query frame"),": a frame that ",(0,o.kt)("em",{parentName:"td"},"does")," ",(0,o.kt)("em",{parentName:"td"},"not")," contain the query object, sometime after the response track but before any subsequent occurrence of the object; ",(0,o.kt)("br",null)," ","(","3",")"," ",(0,o.kt)("strong",{parentName:"td"},"visual crop"),":  bounding box of a single frame from another occurrence of the same object elsewhere in the video (before or after the originally marked instance)"),(0,o.kt)("td",{parentName:"tr",align:null},"~","403h")),(0,o.kt)("tr",{parentName:"tbody"},(0,o.kt)("td",{parentName:"tr",align:null},(0,o.kt)("strong",{parentName:"td"},"Forecasting + Hands & Objects (FHO)")),(0,o.kt)("td",{parentName:"tr",align:null}),(0,o.kt)("td",{parentName:"tr",align:null})),(0,o.kt)("tr",{parentName:"tbody"},(0,o.kt)("td",{parentName:"tr",align:null},(0,o.kt)("a",{parentName:"td",href:"#stage-1---critical-frames"},"1 Critical Frames")),(0,o.kt)("td",{parentName:"tr",align:null},"Pre-condition (PRE), CONTACT, point of no return (PNR), and post-condition (Post) frames for each narrated action in a video"),(0,o.kt)("td",{parentName:"tr",align:null},"~","120h")),(0,o.kt)("tr",{parentName:"tbody"},(0,o.kt)("td",{parentName:"tr",align:null},(0,o.kt)("a",{parentName:"td",href:"#stage-2---pre-condition"},"2 Pre-condition")),(0,o.kt)("td",{parentName:"tr",align:null},"Bounding boxes and roles for hands (right/left) and objects (objects of change and tools) for each frame from CONTACT to PRE"),(0,o.kt)("td",{parentName:"tr",align:null})),(0,o.kt)("tr",{parentName:"tbody"},(0,o.kt)("td",{parentName:"tr",align:null},(0,o.kt)("a",{parentName:"td",href:"#stage-3---post-condition"},"3 Post-condition")),(0,o.kt)("td",{parentName:"tr",align:null},"Bounding boxes and roles for hands and objects for each frame from CONTACT to POST"),(0,o.kt)("td",{parentName:"tr",align:null})),(0,o.kt)("tr",{parentName:"tbody"},(0,o.kt)("td",{parentName:"tr",align:null},(0,o.kt)("strong",{parentName:"td"},(0,o.kt)("a",{parentName:"strong",href:"#audio-visual-diarization--social-avs"},"Audio-Visual Diarization & Social")," (AVS)")),(0,o.kt)("td",{parentName:"tr",align:null}),(0,o.kt)("td",{parentName:"tr",align:null})),(0,o.kt)("tr",{parentName:"tbody"},(0,o.kt)("td",{parentName:"tr",align:null},(0,o.kt)("a",{parentName:"td",href:"#av-step-0-automated-face-head-detection"},"AV0: Automated Face & Head Detection")),(0,o.kt)("td",{parentName:"tr",align:null},"Automated overlaid bounding boxes for faces in video clips"),(0,o.kt)("td",{parentName:"tr",align:null},"50h")),(0,o.kt)("tr",{parentName:"tbody"},(0,o.kt)("td",{parentName:"tr",align:null},(0,o.kt)("a",{parentName:"td",href:"#av-step-1-face-head-tracks-correction"},"AV1: Face & Head Tracks Correction")),(0,o.kt)("td",{parentName:"tr",align:null},"Manually adjusted overlaid bounding boxes for faces in video clips"),(0,o.kt)("td",{parentName:"tr",align:null})),(0,o.kt)("tr",{parentName:"tbody"},(0,o.kt)("td",{parentName:"tr",align:null},(0,o.kt)("a",{parentName:"td",href:"#av-step-2-speaker-labeling-and-av-anchor-extraction"},"AV2: Speaker Labeling and AV anchor extraction")),(0,o.kt)("td",{parentName:"tr",align:null},"Anonymous Person IDs for each Face Track in video clip"),(0,o.kt)("td",{parentName:"tr",align:null})),(0,o.kt)("tr",{parentName:"tbody"},(0,o.kt)("td",{parentName:"tr",align:null},(0,o.kt)("a",{parentName:"td",href:"#av-step-3-speech-segmentation-per-speaker"},"AV3: Speech Segmentation (Per Speaker)")),(0,o.kt)("td",{parentName:"tr",align:null},"Temporal segments for voice activity for the camera wearer and for each Person ID"),(0,o.kt)("td",{parentName:"tr",align:null})),(0,o.kt)("tr",{parentName:"tbody"},(0,o.kt)("td",{parentName:"tr",align:null},(0,o.kt)("a",{parentName:"td",href:"#av-step-4-transcription"},"AV4: Transcription")),(0,o.kt)("td",{parentName:"tr",align:null},"Video clip audio transcriptions"),(0,o.kt)("td",{parentName:"tr",align:null})),(0,o.kt)("tr",{parentName:"tbody"},(0,o.kt)("td",{parentName:"tr",align:null},(0,o.kt)("a",{parentName:"td",href:"#av-step-5-correcting-speech-transcriptions-wip"},"AV5: Correcting Speech Transcriptions")),(0,o.kt)("td",{parentName:"tr",align:null},"Corrected Speech Transcription annotations matching voice activity segments and Person IDs from AV2"),(0,o.kt)("td",{parentName:"tr",align:null})),(0,o.kt)("tr",{parentName:"tbody"},(0,o.kt)("td",{parentName:"tr",align:null},(0,o.kt)("a",{parentName:"td",href:"#s-step-1-camera-wearer-attention"},"S1: Camera-Wearer Attention")),(0,o.kt)("td",{parentName:"tr",align:null},"Temporal segments in which a person is looking at the camera wearer"),(0,o.kt)("td",{parentName:"tr",align:null})),(0,o.kt)("tr",{parentName:"tbody"},(0,o.kt)("td",{parentName:"tr",align:null},(0,o.kt)("a",{parentName:"td",href:"#s-step-2-speech-target-classification"},"S2: Speech Target Classification")),(0,o.kt)("td",{parentName:"tr",align:null},"Temporal segments in which a person is talking to the camera wearer"),(0,o.kt)("td",{parentName:"tr",align:null})))),(0,o.kt)("h2",{id:"narrations"},"Narrations"),(0,o.kt)("p",null,(0,o.kt)("strong",{parentName:"p"},"Objective:")," Annotator provides dense written sentence narrations in\nEnglish on a first-person video clip of length 10-30 minutes + a summary\nof the whole video."),(0,o.kt)("p",null,(0,o.kt)("strong",{parentName:"p"},"Motivation:")," Understand what data is available and which data to push\nthrough which annotation phases. Provide a starting point for forming a\ntaxonomy of labels for actions and objects."),(0,o.kt)("p",null,(0,o.kt)("strong",{parentName:"p"},"Annotation task:")),(0,o.kt)("table",null,(0,o.kt)("thead",{parentName:"table"},(0,o.kt)("tr",{parentName:"thead"},(0,o.kt)("th",{parentName:"tr",align:null},(0,o.kt)("strong",{parentName:"th"},"#")),(0,o.kt)("th",{parentName:"tr",align:null},(0,o.kt)("strong",{parentName:"th"},"Step")),(0,o.kt)("th",{parentName:"tr",align:null},(0,o.kt)("strong",{parentName:"th"},"Sub-step")),(0,o.kt)("th",{parentName:"tr",align:null},(0,o.kt)("strong",{parentName:"th"},"Example")))),(0,o.kt)("tbody",{parentName:"table"},(0,o.kt)("tr",{parentName:"tbody"},(0,o.kt)("td",{parentName:"tr",align:null},"1"),(0,o.kt)("td",{parentName:"tr",align:null},(0,o.kt)("em",{parentName:"td"},"Narrate the Complete Video with Temporal Sentences")),(0,o.kt)("td",{parentName:"tr",align:null},"Watch the video from the beginning until something new occurs."),(0,o.kt)("td",{parentName:"tr",align:null},'set the start time as the point when the person has the knife and the tomato, and the end time as the point when the person has finished chopping, then type: "C is chopping a tomato" into the text input. ("C" refers to the camera wearer).')))),(0,o.kt)("p",null,"|--------|------------------|------------------|------------------|\n|        |                  | At that time,    |                  |\n|        |                  | pause the video, |                  |\n|        |                  | mark the         |                  |\n|        |                  | ",(0,o.kt)("em",{parentName:"p"},"temporal        |                  |\n|        |                  | window"),' for      |                  |\n|        |                  | which the        |                  |\n|        |                  | sentence         |                  |\n|        |                  | applies, then    |                  |\n|        |                  | "narrate" what   |                  |\n|        |                  | you see in the   |                  |\n|        |                  | video by typing  |                  |\n|        |                  | in a simple      |                  |\n|        |                  | sentence into    |                  |\n|        |                  | the free-form    |                  |\n|        |                  | text input.      |                  |\n|--------|------------------|------------------|------------------|\n|        |                  | Next, resume     |                  |\n|        |                  | watching the     |                  |\n|        |                  | video. Once you  |                  |\n|        |                  | recognize an     |                  |\n|        |                  | action to        |                  |\n|        |                  | narrate,         |                  |\n|        |                  | immediately      |                  |\n|        |                  | pause again and  |                  |\n|        |                  | repeat.          |                  |\n|--------|------------------|------------------|------------------|\n| 2      | ',(0,o.kt)("em",{parentName:"p"},"Provide a       | As needed, watch | ","#","summary C      |\n|        | Summary of the   | the entire video | fixed their      |\n|        | Entire Video"),'    | on fast forward  | breakfast, ate   |\n|        |                  | to recall the    | it, then got     |\n|        |                  | content of the   | dressed and left |\n|        |                  | entire video.    | the house."      |\n|        |                  |                  |                  |\n|        |                  | Provide a short  |                  |\n|        |                  | summary in text  |                  |\n|        |                  | about the        |                  |\n|        |                  | contents of the  |                  |\n|        |                  | entire video     |                  |\n|        |                  | (1-3 sentences). |                  |\n|        |                  |                  |                  |\n|        |                  | This summary     |                  |\n|        |                  | should convey    |                  |\n|        |                  | the main         |                  |\n|        |                  | setting(s) of    |                  |\n|        |                  | the video clip   |                  |\n|        |                  | (e.g., an        |                  |\n|        |                  | apartment, a     |                  |\n|        |                  | restaurant, a    |                  |\n|        |                  | shop, etc.) as   |                  |\n|        |                  | well as an       |                  |\n|        |                  | overview of what |                  |\n|        |                  | happened.        |                  |\n|--------|------------------|------------------|------------------|'),(0,o.kt)("p",null,(0,o.kt)("strong",{parentName:"p"},"UI Examples")),(0,o.kt)("ul",null,(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("strong",{parentName:"li"},"Narration:"))),(0,o.kt)("p",null,(0,o.kt)("img",{src:n(7458).Z})),(0,o.kt)("ul",null,(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("strong",{parentName:"li"},"Summary:"))),(0,o.kt)("blockquote",null,(0,o.kt)("p",{parentName:"blockquote"},(0,o.kt)("img",{src:n(2287).Z}))),(0,o.kt)("p",null,(0,o.kt)("strong",{parentName:"p"},"Annotated videos examples:")),(0,o.kt)("p",null,"[",(0,o.kt)("a",{parentName:"p",href:"https://drive.google.com/file/d/14NrVdpYT2RyJU_rKG99AkIToIwNO6JEY/view?usp=sharing"},"Example\nreel")),(0,o.kt)("p",null,(0,o.kt)("img",{src:n(4850).Z}),(0,o.kt)("img",{src:n(7064).Z})),(0,o.kt)("p",null,(0,o.kt)("strong",{parentName:"p"},"Annotation Stats")),(0,o.kt)("ul",null,(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("p",{parentName:"li"},(0,o.kt)("strong",{parentName:"p"},"Total hours narrated:")," 3400")),(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("p",{parentName:"li"},(0,o.kt)("strong",{parentName:"p"},"Unique scenarios:")," 51"),(0,o.kt)("blockquote",{parentName:"li"},(0,o.kt)("p",{parentName:"blockquote"},"([",(0,o.kt)("a",{parentName:"p",href:"https://fburl.com/datainsights/oqrnhisc"},"breakdown"),")")))),(0,o.kt)("p",null,(0,o.kt)("img",{src:n(287).Z})),(0,o.kt)("p",null,(0,o.kt)("strong",{parentName:"p"},"Links:")),(0,o.kt)("ul",null,(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("p",{parentName:"li"},"Narration"),(0,o.kt)("blockquote",{parentName:"li"},(0,o.kt)("p",{parentName:"blockquote"},(0,o.kt)("a",{parentName:"p",href:"https://docs.google.com/document/d/1kHHgJFQM2wbm2M81GjyicoZnGfgix7vnIHhEfkcB0_8/edit#heading=h.zb77nl2kkug0"},"notes"),"\nand\n",(0,o.kt)("a",{parentName:"p",href:"https://l.workplace.com/l.php?u=https%3A%2F%2Fdocs.google.com%2Fdocument%2Fd%2F1avjdALDI3x1jrnY3DiCv72GGZJzXSuRRMjbmcQURKS0%2Fedit%3Fusp%3Dsharing&h=AT0SmFl7unFKCRMTaAd_2TRlp8Wc7pA0eZEBsRyDqTA5z_vaAxftnRJsGAtJa1PBX60OS0M98dEFj7bBuOuy797sFTls8HXCPzIrjfegkk1gxJOO3elVYcWiVdl2NOF3W0zO1TepzJVPHXx3HL_K&__tn__=-UK-y-R&c%5B0%5D=AT2NBxuTggKaQcYTPVeWQRgFrhv33HhiCNjdu1zHc2EqWu_nDJd2thvGRuiSyviJKTcpIlGgCiweuV-3X_1fkLBC10oNlFIBGlLAj6sX1A_twCFkuq2dCpP__mpZm_HrKDiRn-BIDyrsuNnymY9Kq2LGA3382FSPPwXvZdK2TX8ksWeu8KPPsuxOdCoRRQwJMmy6"},"instructions")))),(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("p",{parentName:"li"},(0,o.kt)("a",{parentName:"p",href:"https://docs.google.com/presentation/d/1es_hniyef5bGhtMyeSZkBfbdeXKwElPBjT0YXxr7BvA/edit?usp=sharing"},"Narration analysis"))),(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("p",{parentName:"li"},(0,o.kt)("a",{parentName:"p",href:"https://l.workplace.com/l.php?u=https%3A%2F%2Fdocs.google.com%2Fspreadsheets%2Fd%2F1w1dW1-IyqvufD-X_3SFSBBdLAhOy7JZbNSbhZjDel6I%2Fedit%23gid%3D0&h=AT0JEXfOJJdon1Fc0QP5lnJKL4hMqBvLTnHJPXJleRbSCBAuFMzwiFGE07hyz_YKspJB68Do3y5pyan4963Npz9a4oIBpDhbT1515yy1pJ1uAV0gxJhvCp5EtO-ENJI1yCVueixUaClGp8SIizl6&__tn__=-UK-y-R&c%5B0%5D=AT2NBxuTggKaQcYTPVeWQRgFrhv33HhiCNjdu1zHc2EqWu_nDJd2thvGRuiSyviJKTcpIlGgCiweuV-3X_1fkLBC10oNlFIBGlLAj6sX1A_twCFkuq2dCpP__mpZm_HrKDiRn-BIDyrsuNnymY9Kq2LGA3382FSPPwXvZdK2TX8ksWeu8KPPsuxOdCoRRQwJMmy6"},"Scenario breakdown")))),(0,o.kt)("h2",{id:"benchmark-annotations"},"Benchmark Annotations"),(0,o.kt)("p",null,(0,o.kt)("img",{src:n(1451).Z})),(0,o.kt)("table",null,(0,o.kt)("thead",{parentName:"table"},(0,o.kt)("tr",{parentName:"thead"},(0,o.kt)("th",{parentName:"tr",align:null},(0,o.kt)("strong",{parentName:"th"},"Target")),(0,o.kt)("th",{parentName:"tr",align:null},(0,o.kt)("strong",{parentName:"th"},"#")),(0,o.kt)("th",{parentName:"tr",align:null},(0,o.kt)("strong",{parentName:"th"},"Benchmark task")),(0,o.kt)("th",{parentName:"tr",align:null},(0,o.kt)("strong",{parentName:"th"},"Research Goal")))),(0,o.kt)("tbody",{parentName:"table"},(0,o.kt)("tr",{parentName:"tbody"},(0,o.kt)("td",{parentName:"tr",align:null},(0,o.kt)("strong",{parentName:"td"},"Places")),(0,o.kt)("td",{parentName:"tr",align:null},"1"),(0,o.kt)("td",{parentName:"tr",align:null},(0,o.kt)("a",{parentName:"td",href:"#episodic-memory"},"Episodic Memory")),(0,o.kt)("td",{parentName:"tr",align:null},"Allow an Assistant user to ask free-form, natural language questions, with the answer brought back after analyzing past video (",(0,o.kt)("em",{parentName:"td"},"When was the last time I changed the batteries in the smoke detector?"),").")),(0,o.kt)("tr",{parentName:"tbody"},(0,o.kt)("td",{parentName:"tr",align:null},(0,o.kt)("strong",{parentName:"td"},"Objects")),(0,o.kt)("td",{parentName:"tr",align:null},"2"),(0,o.kt)("td",{parentName:"tr",align:null},(0,o.kt)("a",{parentName:"td",href:"#forecasting--hands--objects-fho"},"Forecasting")),(0,o.kt)("td",{parentName:"tr",align:null},"To intelligently deliver notifications to a user, an AR system must understand how an action or piece of information may impact the future state of the world.")),(0,o.kt)("tr",{parentName:"tbody"},(0,o.kt)("td",{parentName:"tr",align:null}),(0,o.kt)("td",{parentName:"tr",align:null},"3"),(0,o.kt)("td",{parentName:"tr",align:null},(0,o.kt)("a",{parentName:"td",href:"#forecasting--hands--objects-fho"},"Hands-Object interaction")),(0,o.kt)("td",{parentName:"tr",align:null},"AR applications, e.g. providing users instructions in their egocentric real-world view to accomplish tasks (e.g., cooking a recipe).")),(0,o.kt)("tr",{parentName:"tbody"},(0,o.kt)("td",{parentName:"tr",align:null},(0,o.kt)("strong",{parentName:"td"},"People")),(0,o.kt)("td",{parentName:"tr",align:null},"4"),(0,o.kt)("td",{parentName:"tr",align:null},(0,o.kt)("a",{parentName:"td",href:"#audio-visual-diarization--social-avs"},"Audio-visual Diarization")),(0,o.kt)("td",{parentName:"tr",align:null},"To effectively aid people in daily life scenarios, augmented reality must be able to detect and track sounds, responding to users queries or information needs.")),(0,o.kt)("tr",{parentName:"tbody"},(0,o.kt)("td",{parentName:"tr",align:null}),(0,o.kt)("td",{parentName:"tr",align:null},"5"),(0,o.kt)("td",{parentName:"tr",align:null},(0,o.kt)("a",{parentName:"td",href:"#audio-visual-diarization--social-avs"},"Social interactions")),(0,o.kt)("td",{parentName:"tr",align:null},"Recognize people's interactions, their roles, and their attention within collaborative and competitive scenarios within a range of social interactions captured in the Ego4D data.")))),(0,o.kt)("h2",{id:"episodic-memory"},"Episodic Memory"),(0,o.kt)("p",null,(0,o.kt)("strong",{parentName:"p"},"Motivation"),": Augment human memory through personal semantic video\nindex for an always-on wearable camera"),(0,o.kt)("p",null,(0,o.kt)("strong",{parentName:"p"},"Objective"),": Given long first-person video, ",(0,o.kt)("em",{parentName:"p"},"localize")," answers for\nqueries about objects and events from first-person experience"),(0,o.kt)("p",null,(0,o.kt)("em",{parentName:"p"},"Who did I sit by at the party? Where are my keys? When did I change the batteries? How often did I read to my child last week? Did I leave the window open?",".","..")),(0,o.kt)("p",null,(0,o.kt)("strong",{parentName:"p"},"Query types (annotation sub-tasks)"),":"),(0,o.kt)("p",null,"a.  Natural language queries (response = temporal)"),(0,o.kt)("p",null,"b.  Moments queries (response = temporal)"),(0,o.kt)("p",null,"c.  Visual/object queries (response = temporal+spatial)"),(0,o.kt)("h3",{id:"natural-language-queries"},"Natural Language Queries"),(0,o.kt)("h3",{id:""},(0,o.kt)("img",{src:n(6217).Z})),(0,o.kt)("p",null,(0,o.kt)("strong",{parentName:"p"},"Objective:")," Create and annotate ",(0,o.kt)("strong",{parentName:"p"},"N (N=length of video in minutes)"),"\ninteresting questions and their corresponding answers for the given\nvideo."),(0,o.kt)("p",null,(0,o.kt)("strong",{parentName:"p"},"Annotation Task")," (see ",(0,o.kt)("a",{parentName:"p",href:"https://docs.google.com/document/d/1RGbm4BjKt8bZ6a95gYno8DJemuCZBhM2d6WWt_W3vLY/edit?usp=sharing"},"Annotation instructions"),")",(0,o.kt)("strong",{parentName:"p"},":")),(0,o.kt)("p",null,"+--------+------------------+------------------+------------------+\n| ",(0,o.kt)("strong",{parentName:"p"},"#")," | ",(0,o.kt)("strong",{parentName:"p"},"Step"),"         | ",(0,o.kt)("strong",{parentName:"p"},"Sub-step"),"     | ",(0,o.kt)("strong",{parentName:"p"},"Example"),"      |\n+========+==================+==================+==================+\n| 0      | ",(0,o.kt)("em",{parentName:"p"},"Annotator       |                  |                  |\n|        | watches video"),"   |                  |                  |\n+--------+------------------+------------------+------------------+\n| 1      | ",(0,o.kt)("em",{parentName:"p"},"Asks free-form  | -   Select an    | -                |\n|        | natural language |     interesting  | ","[Template]",': |\n|        | query at end of  |     query        |     "What ',(0,o.kt)("strong",{parentName:"em"},"X"),"  |\n|        | video, selecting |     template &   |     is ",(0,o.kt)("strong",{parentName:"em"},"Y"),'?"   |\n|        | from list of     |     template     |                  |\n|        | query            |     category     | -   [Template    |\n|        | templates.'),"      |                  |                  |\n|        |                  | -   Paraphrase   |  ","[Category]",': |\n|        |                  |     question in  |     "Objects"    |\n|        |                  |     the past     |                  |\n|        |                  |     tense.       | -   ',"[Paraphrased |\n|        |                  |                  |     query:]",' |\n|        |                  |                  |     "What        |\n|        |                  |                  |     ',(0,o.kt)("strong",{parentName:"p"},"color"),"    |\n|        |                  |                  |     shirt did    |\n|        |                  |                  |     ",(0,o.kt)("strong",{parentName:"p"},"the person |\n|        |                  |                  |     performing   |\n|        |                  |                  |     on the       |\n|        |                  |                  |     road"),'       |\n|        |                  |                  |     wear?"       |\n+--------+------------------+------------------+------------------+\n|        |                  | Using            | First free-form  |\n|        |                  | ',(0,o.kt)("strong",{parentName:"p"},'"free-form"'),'  | query slot:      |\n|        |                  | text, fill the   | "',(0,o.kt)("strong",{parentName:"p"},"color"),'"      |\n|        |                  | ',(0,o.kt)("strong",{parentName:"p"},"query slots"),"  |                  |\n|        |                  | (X, Y, ",".",'..) in  | Second free-form |\n|        |                  | the template to  | query slot:      |\n|        |                  | form a           | "',(0,o.kt)("strong",{parentName:"p"},"the shirt of  |\n|        |                  | meaningful       | the person       |\n|        |                  | question         | performing on    |\n|        |                  | equivalent to    | the road"),'"      |\n|        |                  | the paraphrase.  |                  |\n+--------+------------------+------------------+------------------+\n|        |                  | Pick the closest | -   ',"[Paraphrased |\n|        |                  | verb for each of |     query]",": |\n|        |                  | the slots in the |     What         |\n|        |                  | respective       |                  |\n|        |                  | drop-down menus  |   ",(0,o.kt)("strong",{parentName:"p"},"instrument")," |\n|        |                  |                  |     was ",(0,o.kt)("strong",{parentName:"p"},"the    |\n|        |                  |                  |     musician     |\n|        |                  |                  |     playing"),"?   |\n|        |                  |                  |                  |\n|        |                  |                  | -   ","[First verb  |\n|        |                  |                  |     drop-down selection]",': |\n|        |                  |                  |     "',"[","VERB NOT APPLICABLE","]",'" |\n|        |                  |                  |                  |\n|        |                  |                  | -   Second verb  |\n|        |                  |                  |     drop-down    |\n|        |                  |                  |     selection:   |\n|        |                  |                  |     "',(0,o.kt)("strong",{parentName:"p"},"play"),'"   |\n+--------+------------------+------------------+------------------+\n| 2      | ',(0,o.kt)("em",{parentName:"p"},"Identifies the  | Seek in the      |                  |\n|        | temporal         | video to the     |                  |\n|        | response window  | temporal window  |                  |\n|        | from which       | where the        |                  |\n|        | answer can be    | response to the  |                  |\n|        | deduced"),"         | natural language |                  |\n|        |                  | query can be     |                  |\n|        |                  | deduced visually |                  |\n|        |                  |                  |                  |\n|        |                  | Specify query to |                  |\n|        |                  | have only one    |                  |\n|        |                  | valid,           |                  |\n|        |                  | contiguous       |                  |\n|        |                  | temporal window  |                  |\n|        |                  | response         |                  |\n+--------+------------------+------------------+------------------+\n| 3      | ",(0,o.kt)("em",{parentName:"p"},"Repeat this     |                  |                  |\n|        | process N=length |                  |                  |\n|        | of video in      |                  |                  |\n|        | minutes creating |                  |                  |\n|        | N diverse        |                  |                  |\n|        | language         |                  |                  |\n|        | queries"),"         |                  |                  |\n+--------+------------------+------------------+------------------+"),(0,o.kt)("p",null,(0,o.kt)("strong",{parentName:"p"},"UI Examples:")),(0,o.kt)("p",null,(0,o.kt)("img",{src:n(9799).Z})),(0,o.kt)("p",null,(0,o.kt)("strong",{parentName:"p"},"Annotated UI Example:")),(0,o.kt)("p",null,"  ",(0,o.kt)("strong",{parentName:"p"},"#"),"   ",(0,o.kt)("strong",{parentName:"p"},"Name"),"                                         ",(0,o.kt)("strong",{parentName:"p"},"Example")),(0,o.kt)("hr",null),(0,o.kt)("p",null,"  1        Query Set Label                                  ",(0,o.kt)("em",{parentName:"p"},"Query Set 1"),"\n2        Template Query Category                          ",(0,o.kt)("em",{parentName:"p"},"Object"),"\n3        Template                                         ",(0,o.kt)("em",{parentName:"p"},"Where is object X before/after event Y?"),"\n4        Paraphrased template in natural language         ",(0,o.kt)("em",{parentName:"p"},"Where were the blue pliers before I picked them up?"),"\n5        First slot (X)                                   ",(0,o.kt)("em",{parentName:"p"},"Blue pliers"),"\n6        Dominant Verb Taxonomy for the first slot (X)    Verb: ",(0,o.kt)("em",{parentName:"p"},"[","VERB NOT APPLICABLE","]"),"\n7        Second slot (Y)                                  ",(0,o.kt)("em",{parentName:"p"},"I picked them up"),"\n8        Dominant Verb Taxonomy for the second slot (Y)   ",(0,o.kt)("em",{parentName:"p"},"pick")),(0,o.kt)("p",null,(0,o.kt)("img",{src:n(2140).Z})),(0,o.kt)("p",null,(0,o.kt)("strong",{parentName:"p"},"Annotated videos examples:")),(0,o.kt)("p",null,"[",(0,o.kt)("a",{parentName:"p",href:"https://drive.google.com/file/d/14NrVdpYT2RyJU_rKG99AkIToIwNO6JEY/view?usp=sharing"},"Example (cooking, bike mechanic)")),(0,o.kt)("p",null,(0,o.kt)("img",{src:n(3299).Z})),(0,o.kt)("p",null,(0,o.kt)("strong",{parentName:"p"},"Annotation Stats (Jul 21):")),(0,o.kt)("ul",null,(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("p",{parentName:"li"},(0,o.kt)("strong",{parentName:"p"},"Total hours annotated:")," ","~","240 (x2; one for each vendor)")),(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("p",{parentName:"li"},(0,o.kt)("strong",{parentName:"p"},"Distribution over question types:")))),(0,o.kt)("p",null,(0,o.kt)("img",{src:n(3915).Z})),(0,o.kt)("ul",null,(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("strong",{parentName:"li"},"Scenario breakdown:"))),(0,o.kt)("p",null,(0,o.kt)("img",{src:n(5499).Z})),(0,o.kt)("h3",{id:"moments"},"Moments"),(0,o.kt)("p",null,(0,o.kt)("img",{src:n(8622).Z})),(0,o.kt)("p",null,(0,o.kt)("strong",{parentName:"p"},"Objective:")," Localize high level events in a long video clip ","-","-\nmarking any instance of provided activity categories with a temporal\nwindow and the activity's name."),(0,o.kt)("p",null,(0,o.kt)("strong",{parentName:"p"},"Motivation:"),' Learn to detect activities or "moments" and their\ntemporal extent in the video. In the context of episodic memory, the\nimplicit query from a user would be "When is the last time I did X?",\nand the response from the system would be to show the time window where\nactivity X was last seen.'),(0,o.kt)("p",null,(0,o.kt)("strong",{parentName:"p"},"Annotation Task")," (see ",(0,o.kt)("a",{parentName:"p",href:"https://docs.google.com/document/d/1lGtcGjxYOOQsf9SalVehEocqjsh26j0LbmhGucojkOw/edit"},"Annotation instructions"),")",(0,o.kt)("strong",{parentName:"p"},":")),(0,o.kt)("p",null,"+--------+------------------+------------------+------------------+\n| ",(0,o.kt)("strong",{parentName:"p"},"#")," | ",(0,o.kt)("strong",{parentName:"p"},"Step"),"         | ",(0,o.kt)("strong",{parentName:"p"},"Sub-step"),"     | ",(0,o.kt)("strong",{parentName:"p"},"Example"),"      |\n+========+==================+==================+==================+\n| 1      | ",(0,o.kt)("em",{parentName:"p"},"Review the      |                  | ![]              |\n|        | Taxonomy"),"        |                  | (media/image15.p |\n|        |                  |                  | ng) |\n+--------+------------------+------------------+------------------+\n| 2      | ",(0,o.kt)("em",{parentName:"p"},"Annotate the    | 1.  Play the     | "),"See [","[UI        |\n|        | Video*           |     video until  | Examples]","  |\n|        |                  |     you observe  | (#llbjhw5qjwgg)* |\n|        |                  |     an activity, |                  |\n|        |                  |     then pause.  |                  |\n|        |                  |                  |                  |\n|        |                  | 2.  Draw a       |                  |\n|        |                  |     temporal     |                  |\n|        |                  |     window       |                  |\n|        |                  |     around the   |                  |\n|        |                  |     time span    |                  |\n|        |                  |     where the    |                  |\n|        |                  |     activity     |                  |\n|        |                  |     occurs       |                  |\n|        |                  |                  |                  |\n|        |                  | 3.  Select from  |                  |\n|        |                  |     the dropdown |                  |\n|        |                  |     list the     |                  |\n|        |                  |     name for     |                  |\n|        |                  |     that         |                  |\n|        |                  |     activity     |                  |\n|        |                  |                  |                  |\n|        |                  | 4.  Play the     |                  |\n|        |                  |     video from   |                  |\n|        |                  |     the start of |                  |\n|        |                  |     the previous |                  |\n|        |                  |     activity,    |                  |\n|        |                  |     repeat steps |                  |\n|        |                  |     1-3          |                  |\n+--------+------------------+------------------+------------------+"),(0,o.kt)("p",null,(0,o.kt)("strong",{parentName:"p"},"UI Examples:")),(0,o.kt)("p",null,(0,o.kt)("img",{src:n(7301).Z})),(0,o.kt)("p",null,(0,o.kt)("strong",{parentName:"p"},"Annotation Stats (Jul 21):")),(0,o.kt)("ul",null,(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("strong",{parentName:"li"},"Total hours annotated:")," ","~","300 (x3 raters)")),(0,o.kt)("h3",{id:"visual-object-queries"},"Visual Object Queries"),(0,o.kt)("p",null,(0,o.kt)("img",{src:n(874).Z})),(0,o.kt)("p",null,(0,o.kt)("strong",{parentName:"p"},"Objective:")," Localize past instances of a given object that appears at\nleast twice in different parts of the video."),(0,o.kt)("p",null,(0,o.kt)("strong",{parentName:"p"},"Motivation:"),' Support an object search application for video in which\na user asks at time T "where did I last see X?", and the system scans\nback in the video history starting at query frame T, finds the most\nrecent instance of X, and outlines it in a short track',(0,o.kt)("strong",{parentName:"p"},".")),(0,o.kt)("p",null,(0,o.kt)("strong",{parentName:"p"},"Annotation Task:")," (see ",(0,o.kt)("a",{parentName:"p",href:"https://docs.google.com/document/d/1Ks9qVQjTE16tJXsC3fh-64Rlkoc_qbQafxyu1c6uNYw/edit?usp=sharing"},"Annotation instructions"),")"),(0,o.kt)("p",null,"+--------+------------------+------------------+------------------+\n| ",(0,o.kt)("strong",{parentName:"p"},"#")," | ",(0,o.kt)("strong",{parentName:"p"},"Step"),"         | ",(0,o.kt)("strong",{parentName:"p"},"Sub-step"),"     | ",(0,o.kt)("strong",{parentName:"p"},"Example"),"      |\n+========+==================+==================+==================+\n| 1      | *Identify        | Preview the      |                  |\n|        | ",(0,o.kt)("strong",{parentName:"p"},"query objects  | entire video     |                  |\n|        | *"),"              |                  |                  |\n|        |                  | Identify a set   |                  |\n|        |                  | of N=3           |                  |\n|        |                  | interesting      |                  |\n|        |                  | objects to label |                  |\n|        |                  | as queries (=    |                  |\n|        |                  | objects that     |                  |\n|        |                  | appear at least  |                  |\n|        |                  | twice at         |                  |\n|        |                  | distinct         |                  |\n|        |                  | non-contiguous   |                  |\n|        |                  | parts of the     |                  |\n|        |                  | video clip)      |                  |\n+--------+------------------+------------------+------------------+\n| 2      | *Select a        | -   Select one   | ![]              |\n|        | ",(0,o.kt)("strong",{parentName:"p"},"response       |     occurrence   | (media/image30.g |\n|        | track*"),'         |     of the query | if){width="1.895 |\n|        |                  |     object.      | 8333333333333in" |\n|        |                  |                  | height="1.0694   |\n|        |                  | -   Mark the     | 444444444444in"} |\n|        |                  |     query object |                  |\n|        |                  |     with a       |                  |\n|        |                  |     bounding box |                  |\n|        |                  |     over time,   |                  |\n|        |                  |     from the     |                  |\n|        |                  |     frame the    |                  |\n|        |                  |     object       |                  |\n|        |                  |     enters the   |                  |\n|        |                  |     field of     |                  |\n|        |                  |     view until   |                  |\n|        |                  |     it leaves    |                  |\n|        |                  |     the field of |                  |\n|        |                  |     view, for    |                  |\n|        |                  |     that object  |                  |\n|        |                  |     occurrence.  |                  |\n+--------+------------------+------------------+------------------+\n| 3      | *Select a        | -   Select a     | ',"![               |\n|        | **query frame*** |     frame that   | ]","(media/image9.p |\n|        |                  |     does ",(0,o.kt)("em",{parentName:"p"},"not"),'   | ng){width="1.833 |\n|        |                  |     contain the  | 3333333333333in" |\n|        |                  |     query        | height="1.25in"} |\n|        |                  |     object,      |                  |\n|        |                  |     sometime far |                  |\n|        |                  |     ',(0,o.kt)("em",{parentName:"p"},"after")," that |                  |\n|        |                  |     object       |                  |\n|        |                  |     occurrence,  |                  |\n|        |                  |     but ",(0,o.kt)("em",{parentName:"p"},"before")," |                  |\n|        |                  |     any          |                  |\n|        |                  |     subsequent   |                  |\n|        |                  |     occurrence   |                  |\n|        |                  |     of the       |                  |\n|        |                  |     object.      |                  |\n|        |                  |                  |                  |\n|        |                  | -   Mark the     |                  |\n|        |                  |     time point   |                  |\n|        |                  |     with a large |                  |\n|        |                  |     bounding     |                  |\n|        |                  |     box.         |                  |\n+--------+------------------+------------------+------------------+\n| 4      | *Select a        | -   Find another | ![]              |\n|        | ",(0,o.kt)("strong",{parentName:"p"},"visual crop*"),' |     occurrence   | (media/image11.p |\n|        |                  |     of the same  | ng){width="1.895 |\n|        |                  |     object       | 8333333333333in" |\n|        |                  |     elsewhere in | height="1.25in"} |\n|        |                  |     the video    |                  |\n|        |                  |     (before or   |                  |\n|        |                  |     after the    |                  |\n|        |                  |     originally   |                  |\n|        |                  |     marked       |                  |\n|        |                  |     instance     |                  |\n|        |                  |     from Step 2) |                  |\n|        |                  |                  |                  |\n|        |                  | -   Draw a       |                  |\n|        |                  |     bounding box |                  |\n|        |                  |     in           |                  |\n|        |                  |     ',"[one]","{.ul}   |                  |\n|        |                  |     frame around |                  |\n|        |                  |     that object. |                  |\n+--------+------------------+------------------+------------------+\n| 5      | ",(0,o.kt)("strong",{parentName:"p"},"*Name"),"        |                  |                  |\n|        | ",(0,o.kt)("strong",{parentName:"p"},"the"),"          |                  |                  |\n|        | ",(0,o.kt)("strong",{parentName:"p"},"object")," using |                  |                  |\n|        | the ",(0,o.kt)("strong",{parentName:"p"},"free       |                  |                  |\n|        | text")," box",(0,o.kt)("em",{parentName:"p"},"      |                  |                  |\n+--------+------------------+------------------+------------------+\n| 6      | "),"Repeat Steps    |                  |                  |\n|        | 1-5 three times  |                  |                  |\n|        | for the same     |                  |                  |\n|        | video clip and   |                  |                  |\n|        | different        |                  |                  |\n|        | objects*         |                  |                  |\n+--------+------------------+------------------+------------------+"),(0,o.kt)("p",null,(0,o.kt)("strong",{parentName:"p"},"Annotation Stats (Jul 21):")),(0,o.kt)("ul",null,(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("strong",{parentName:"li"},"Total hours annotated:")," ","~","403")),(0,o.kt)("blockquote",null,(0,o.kt)("p",{parentName:"blockquote"},(0,o.kt)("img",{src:n(2914).Z}))),(0,o.kt)("ul",null,(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("strong",{parentName:"li"},"Scenario breakdown:"))),(0,o.kt)("p",null,(0,o.kt)("img",{src:n(3835).Z})),(0,o.kt)("h2",{id:"forecasting--hands--objects-fho"},"Forecasting + Hands & Objects (FHO)"),(0,o.kt)("p",null,(0,o.kt)("strong",{parentName:"p"},"Objective:")," Recognize object state changes temporally and spatially\n(HO); predict these interactions spatially and temporally before they\nhappen (F)."),(0,o.kt)("p",null,(0,o.kt)("strong",{parentName:"p"},"Motivation:")," Understanding and anticipating human-object\ninteractions."),(0,o.kt)("p",null,(0,o.kt)("strong",{parentName:"p"},"Scenario Distribution:")),(0,o.kt)("p",null,(0,o.kt)("img",{src:n(9850).Z})),(0,o.kt)("p",null,"|----------------------------------|----------------------------------|\n| ",(0,o.kt)("strong",{parentName:"p"},"Annotation"),"                   | ",(0,o.kt)("strong",{parentName:"p"},"Scenario Distribution:"),"       |\n| (Aug 21):**                      |                                  |\n|                                  |                                  |\n| Labeled videos: 1,074            |                                  |\n|                                  |                                  |\n| Labeled clips: 1,672             |                                  |\n|                                  |                                  |\n| Labeled hours: 116.274           |                                  |\n|                                  |                                  |\n| Number of scenarios: 53          |                                  |\n|                                  |                                  |\n| Number of universities: 7        |                                  |\n|                                  |                                  |\n| Number of participants: 397      |                                  |\n|                                  |                                  |\n| Num interactions: 91,002         |                                  |\n|                                  |                                  |\n| Num rejected: 18,839             |                                  |\n|                                  |                                  |\n| Num with state change: 70,718    |                                  |\n|                                  |                                  |\n+----------------------------------+----------------------------------+"),(0,o.kt)("h3",{id:"stage-1---critical-frames"},"Stage 1 - Critical Frames"),(0,o.kt)("p",null,(0,o.kt)("img",{src:n(7824).Z})),(0,o.kt)("p",null,(0,o.kt)("strong",{parentName:"p"},"Objective:")," Annotator watches an egocentric video and marks\npre-condition (PRE), contact, point of no return (PNR), and\npost-condition (Post) frames."),(0,o.kt)("p",null,(0,o.kt)("strong",{parentName:"p"},"Annotation Task")," (See [",(0,o.kt)("a",{parentName:"p",href:"https://docs.google.com/document/d/13BmI98M_4gzd31vYAtQ8wRSLHggpnrts0gOVDTrWnDM/edit?usp=sharing"},"Annotation instructions"),")",(0,o.kt)("strong",{parentName:"p"},":")),(0,o.kt)("p",null,"+--------+------------------+------------------+------------------+\n| ",(0,o.kt)("strong",{parentName:"p"},"#")," | ",(0,o.kt)("strong",{parentName:"p"},"Step"),"         | ",(0,o.kt)("strong",{parentName:"p"},"Sub-step"),"     | ",(0,o.kt)("strong",{parentName:"p"},"Example"),"      |\n+========+==================+==================+==================+\n| 1      | ",(0,o.kt)("em",{parentName:"p"},"Read the        | 1","."," Reject       | "),"Example:",(0,o.kt)("em",{parentName:"p"},' "C    |\n|        | narrated action  | videos that do   | glides hand      |\n|        | to be labeled'),'   | not contain      | planer along the |\n|        |                  | hand-object      | wood"![]         |\n|        |                  | interactions     | (media/image46.p |\n|        |                  |                  | ng){width="1.895 |\n|        |                  | 2',".",' Reject       | 8333333333333in" |\n|        |                  | videos that not  | height="1.0277   |\n|        |                  | contain the      | 777777777777in"} |\n|        |                  | narrated action  |                  |\n+--------+------------------+------------------+------------------+\n| 2      | ',(0,o.kt)("em",{parentName:"p"},"Select the verb | -   If an        | ![]              |\n|        | corresponding to |     appropriate  | (media/image28.p |\n|        | the narration"),'   |     verb is not  | ng){width="1.895 |\n|        |                  |     available,   | 8333333333333in" |\n|        |                  |     select OTHER | height="1.0in"}  |\n|        |                  |     from the     |                  |\n|        |                  |     dropdown and |                  |\n|        |                  |     type in the  |                  |\n|        |                  |     verb in the  |                  |\n|        |                  |     text box.    |                  |\n+--------+------------------+------------------+------------------+\n| 3      | ',(0,o.kt)("em",{parentName:"p"},"Select the      | -   Select one   | ![]              |\n|        | ",(0,o.kt)("strong",{parentName:"em"},"state change   |     > of 8       | (media/image22.p |\n|        | type"),' present   |     > options    | ng){width="1.895 |\n|        | in the video'),'    |     > from the   | 8333333333333in" |\n|        |                  |     > dropdown   | height="1.0277   |\n|        |                  |                  | 777777777777in"} |\n+--------+------------------+------------------+------------------+\n| 4      | ',(0,o.kt)("em",{parentName:"p"},"Mark the        | -   Find the     | ![]              |\n|        | ",(0,o.kt)("strong",{parentName:"em"},"CONTACT"),'      |     > CONTACT    | (media/image47.p |\n|        | (only if         |     > frame      | ng){width="1.895 |\n|        | present),'),'       |                  | 8333333333333in" |\n|        | ',(0,o.kt)("strong",{parentName:"p"},"PRE"),' and      | -   Pause the    | height="1.0138   |\n|        | ',(0,o.kt)("strong",{parentName:"p"},"POST"),' frames. |     > video      | 888888888888in"} |\n|        |                  |                  |                  |\n|        |                  | -   Select the   |                  |\n|        |                  |     > "Contact   |                  |\n|        |                  |     > Frame"     |                  |\n|        |                  |     > from the   |                  |\n|        |                  |     > dropdown   |                  |\n|        |                  |                  |                  |\n|        |                  | -   Repeat the   |                  |\n|        |                  |     > same       |                  |\n|        |                  |     > protocol   |                  |\n|        |                  |     > for PRE    |                  |\n|        |                  |     > and POST   |                  |\n|        |                  |     > frames.    |                  |\n+--------+------------------+------------------+------------------+'),(0,o.kt)("p",null,(0,o.kt)("strong",{parentName:"p"},"PRE, CONTACT, PNR, POST examples:")),(0,o.kt)("p",null,'a.  Example: "light blowtorch"'),(0,o.kt)("blockquote",null,(0,o.kt)("p",{parentName:"blockquote"},(0,o.kt)("img",{src:n(1266).Z}),'{width="5.646893044619422in"\nheight="1.1927088801399826in"}')),(0,o.kt)("p",null,'b.  Example: "put down wood" (object already in hands, no CONTACT'),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre"},'> frame)![](media/image39.jpg){width="4.238373797025372in"\n> height="1.1927088801399826in"}\n')),(0,o.kt)("p",null,"c.  [[VIDEO"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre"},"> EXAMPLES](https://drive.google.com/file/d/1Fvg6ddceiVAbOru69XXB3PExuZAPd7ad/view?usp=sharing)\n")),(0,o.kt)("h3",{id:"stage-2---pre-condition"},"Stage 2 - Pre-condition"),(0,o.kt)("p",null,(0,o.kt)("strong",{parentName:"p"},"Objective:")," Label bounding boxes and roles for hands (right/left) and\nobjects (objects of change and tools)."),(0,o.kt)("p",null,(0,o.kt)("strong",{parentName:"p"},"Annotation Task")," (see [",(0,o.kt)("a",{parentName:"p",href:"https://docs.google.com/document/d/1bjbjJVFEUnl_GnTFmjfZry49_7c7DdR_RBotyjLoGgM/edit?usp=sharing"},"Annotation\ninstructions"),"\nand [",(0,o.kt)("a",{parentName:"p",href:"https://drive.google.com/file/d/14gXr6yMb815L79jp0QN_n2X9e_OXpqIa/view"},"video\ntutorial"),")\n","[Note]","{.ul}: clips annotated from previous stage play in reverse from\nCONTACT to PRE frame:"),(0,o.kt)("p",null,"+--------+------------------+------------------+------------------+\n| ",(0,o.kt)("strong",{parentName:"p"},"#")," | ",(0,o.kt)("strong",{parentName:"p"},"Step"),"         | ",(0,o.kt)("strong",{parentName:"p"},"Sub-step"),"     | ",(0,o.kt)("strong",{parentName:"p"},"Example"),"      |\n+========+==================+==================+==================+\n| 1      | ",(0,o.kt)("em",{parentName:"p"},"Read the        |                  | "),"Example:",(0,o.kt)("em",{parentName:"p"},' "C    |\n|        | narrated action  |                  | straightens the  |\n|        | to be labeled'),'   |                  | cloth"![]        |\n|        |                  |                  | (media/image25.p |\n|        |                  |                  | ng){width="1.895 |\n|        |                  |                  | 8333333333333in" |\n|        |                  |                  | height="0.9861   |\n|        |                  |                  | 111111111112in"} |\n+--------+------------------+------------------+------------------+\n| 2      | ',(0,o.kt)("em",{parentName:"p"},"Label the       | Label ",(0,o.kt)("strong",{parentName:"em"},"right    | ![]              |\n|        | contact frame    | and left hands"),' | (media/image29.p |\n|        | (first frame     | (if visible), by | ng){width="1.895 |\n|        | shown)'),'          | correcting the   | 8333333333333in" |\n|        |                  | existing         | height="0.9722   |\n|        |                  | bounding box or  | 222222222222in"} |\n|        |                  | adding a new     |                  |\n|        |                  | one.             |                  |\n+--------+------------------+------------------+------------------+\n|        |                  | \u200b\u200bLabel the      | ![]              |\n|        |                  | ',(0,o.kt)("strong",{parentName:"p"},"object(s) of   | (media/image36.p |\n|        |                  | change"),':        | ng){width="1.895 |\n|        |                  |                  | 8333333333333in" |\n|        |                  | -   Draw the     | height="0.9722   |\n|        |                  |     ','[bounding    | 222222222222in"} |\n|        |                  |     box]',"{.ul}    |                  |\n|        |                  |                  |                  |\n|        |                  | -   Mark the     |                  |\n|        |                  |     object as    |                  |\n|        |                  |     Object of    |                  |\n|        |                  |     change       |                  |\n|        |                  |                  |                  |\n|        |                  | -   Select the   |                  |\n|        |                  |     ","[name of the |                  |\n|        |                  |     object]","{.ul} |                  |\n|        |                  |     from list    |                  |\n|        |                  |     provided     |                  |\n|        |                  |                  |                  |\n|        |                  | -   Select       |                  |\n|        |                  |     ","[instance    |                  |\n|        |                  |     ID]","{.ul}     |                  |\n|        |                  |     (for         |                  |\n|        |                  |     multiple     |                  |\n|        |                  |     objects of   |                  |\n|        |                  |     the same     |                  |\n|        |                  |     type)        |                  |\n|        |                  |                  |                  |\n|        |                  | -   Repeat for   |                  |\n|        |                  |     each object  |                  |\n|        |                  |     of change    |                  |\n+--------+------------------+------------------+------------------+\n|        |                  | > Label the      | ![]              |\n|        |                  | > ",(0,o.kt)("strong",{parentName:"p"},"tool"),' (if   | (media/image27.p |\n|        |                  | > present):      | ng){width="1.895 |\n|        |                  |                  | 8333333333333in" |\n|        |                  | -   Draw the     | height="0.9722   |\n|        |                  |     > ','[bounding  | 222222222222in"} |\n|        |                  |     > box]',"{.ul}  |                  |\n|        |                  |                  |                  |\n|        |                  | -   Mark the     |                  |\n|        |                  |     > object as  |                  |\n|        |                  |     > Tool       |                  |\n|        |                  |                  |                  |\n|        |                  | -   Select the   |                  |\n|        |                  |     > ","[name of   |                  |\n|        |                  |     > the        |                  |\n|        |                  |     > tool]","{.ul} |                  |\n|        |                  |     > from list  |                  |\n|        |                  |     > provided   |                  |\n|        |                  |                  |                  |\n|        |                  | -   Select       |                  |\n|        |                  |     > ","[instance  |                  |\n|        |                  |     > ID]","{.ul}   |                  |\n|        |                  |     > (for       |                  |\n|        |                  |     > multiple   |                  |\n|        |                  |     > objects of |                  |\n|        |                  |     > the same   |                  |\n|        |                  |     > type)      |                  |\n+--------+------------------+------------------+------------------+\n| 3      | ",(0,o.kt)("em",{parentName:"p"},"Label the       | -   Go to the    | ![]              |\n|        | remaining        |     > next frame | (media/image41.p |\n|        | frames"),'          |                  | ng){width="1.895 |\n|        |                  | -   Adjust the   | 8333333333333in" |\n|        |                  |     > hand boxes | height="0.9861   |\n|        |                  |                  | 111111111112in"} |\n|        |                  | -   Adjust the   |                  |\n|        |                  |     > object of  |                  |\n|        |                  |     > change box |                  |\n|        |                  |                  |                  |\n|        |                  | -   Adjust the   |                  |\n|        |                  |     > tool box   |                  |\n|        |                  |     > (if        |                  |\n|        |                  |     > present)   |                  |\n|        |                  |                  |                  |\n|        |                  | -   Repeat for   |                  |\n|        |                  |     > the        |                  |\n|        |                  |     > remaining  |                  |\n|        |                  |     > frames     |                  |\n+--------+------------------+------------------+------------------+'),(0,o.kt)("h3",{id:"stage-3---post-condition"},"Stage 3 - Post-condition"),(0,o.kt)("p",null,(0,o.kt)("strong",{parentName:"p"},"Objective:")," Label bounding boxes and roles for hands and objects\n(from Contact to Post frame)."),(0,o.kt)("p",null,(0,o.kt)("strong",{parentName:"p"},"Annotation Task")," (see [",(0,o.kt)("a",{parentName:"p",href:"https://docs.google.com/document/d/18kSRpBNhYirvlFDF6MplpkiRLstGh5BMko4DKHwq_9o/edit?usp=sharing"},"Annotation\ninstructions"),")\n","[Note]","{.ul}: clips annotated from Stage 1 play from CONTACT to POST\nframe:"),(0,o.kt)("p",null,"+--------+------------------+------------------+------------------+\n| ",(0,o.kt)("strong",{parentName:"p"},"#")," | ",(0,o.kt)("strong",{parentName:"p"},"Step"),"         | ",(0,o.kt)("strong",{parentName:"p"},"Sub-step"),"     | ",(0,o.kt)("strong",{parentName:"p"},"Example"),"      |\n+========+==================+==================+==================+\n| 1      | ",(0,o.kt)("em",{parentName:"p"},"Read the        |                  | "),"Example:",(0,o.kt)("em",{parentName:"p"},' "C    |\n|        | narrated action  |                  | straightens the  |\n|        | to be labeled'),'   |                  | cloth"![]        |\n|        |                  |                  | (media/image25.p |\n|        |                  |                  | ng){width="1.895 |\n|        |                  |                  | 8333333333333in" |\n|        |                  |                  | height="0.9861   |\n|        |                  |                  | 111111111112in"} |\n+--------+------------------+------------------+------------------+\n| 2      | ',(0,o.kt)("em",{parentName:"p"},"Check the       | Contact frame    |                  |\n|        | contact frame    | will already be  |                  |\n|        | (first frame     | labeled with:    |                  |\n|        | shown)"),"          |                  |                  |\n|        |                  | -   Left hand    |                  |\n|        |                  |     > (if        |                  |\n|        |                  |     > visible)   |                  |\n|        |                  |                  |                  |\n|        |                  | -   Right hand   |                  |\n|        |                  |     > (if        |                  |\n|        |                  |     > visible)   |                  |\n|        |                  |                  |                  |\n|        |                  | -   Active       |                  |\n|        |                  |     > object     |                  |\n|        |                  |                  |                  |\n|        |                  | -   Tool (if     |                  |\n|        |                  |                  |                  |\n|        |                  |    > applicable) |                  |\n+--------+------------------+------------------+------------------+\n|        |                  |                  |                  |\n+--------+------------------+------------------+------------------+\n| 3      | ",(0,o.kt)("em",{parentName:"p"},"Label the       | -   Go to the    | ![]              |\n|        | remaining        |     > next frame | (media/image37.p |\n|        | frames"),'          |                  | ng){width="1.895 |\n|        |                  | -   Adjust (or   | 8333333333333in" |\n|        |                  |     > add) the   | height="0.9722   |\n|        |                  |     > hand boxes | 222222222222in"} |\n|        |                  |                  |                  |\n|        |                  | -   Adjust the   |                  |\n|        |                  |     > object of  |                  |\n|        |                  |     > change box |                  |\n|        |                  |                  |                  |\n|        |                  | -   Adjust the   |                  |\n|        |                  |     > tool box   |                  |\n|        |                  |     > (if        |                  |\n|        |                  |     > present)   |                  |\n|        |                  |                  |                  |\n|        |                  | -   Repeat for   |                  |\n|        |                  |     > the        |                  |\n|        |                  |     > remaining  |                  |\n|        |                  |     > frames     |                  |\n+--------+------------------+------------------+------------------+'),(0,o.kt)("h2",{id:"audio-visual-diarization--social-avs"},"Audio-Visual Diarization & Social (AVS)"),(0,o.kt)("p",null,(0,o.kt)("strong",{parentName:"p"},"Objective:")),(0,o.kt)("ul",null,(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("p",{parentName:"li"},(0,o.kt)("strong",{parentName:"p"},"AV"),": Locate each speaker spatially and temporally, segment and"),(0,o.kt)("blockquote",{parentName:"li"},(0,o.kt)("p",{parentName:"blockquote"},"transcribe the speech content (in a given video), assign each\nspeaker an anonymous label. [",(0,o.kt)("a",{parentName:"p",href:"https://docs.google.com/document/d/188OjXu_UvwB2vLX5SestusNuhdao7QcZ11BbuKd5-8U/edit?usp=sharing"},"Audio Visual Detection & Tracking\nAnnotations Summary\n","[","Updated","]")))),(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("p",{parentName:"li"},(0,o.kt)("strong",{parentName:"p"},"S:")," predict the following social cues:"),(0,o.kt)("ul",{parentName:"li"},(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("p",{parentName:"li"},"Who is talking to the camera wearer at each time segment")),(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("p",{parentName:"li"},"Who is looking at the camera wearer at each time segment"))))),(0,o.kt)("p",null,(0,o.kt)("strong",{parentName:"p"},"Motivation:")," Understand conversational behavior from the naturalistic\negocentric perspective; capture low level detection, segmentation and\ntracking attributes of people\\'s interactions in a scene, and more high\nlevel (intent/emotions driven) attributes that drive social and group\nconversations in the real world."),(0,o.kt)("p",null,"+--------------------------------+----------------------------+\n| ",(0,o.kt)("strong",{parentName:"p"},"Annotation stats (Aug 21):")," | ",(0,o.kt)("strong",{parentName:"p"},"Scenario Distribution:")," |\n|                                |                            |\n| TBU                            |                            |\n|                                |                            |\n| Source:                        |                            |\n+--------------------------------+----------------------------+"),(0,o.kt)("h3",{id:"av-step-0-automated-face--head-detection"},"AV Step 0: Automated Face & Head Detection"),(0,o.kt)("p",null,"A face detection algorithm is run on the given input video to detect all\nthe faces. The resulting bounding boxes are going to be populated and\noverlaid on the input video."),(0,o.kt)("h3",{id:"av-step-1-face--head-tracks-correction"},"AV Step 1: Face & Head Tracks Correction"),(0,o.kt)("p",null,(0,o.kt)("strong",{parentName:"p"},"Objective:")," Have a correct face bounding box around all the faces\nvisible in the video"),(0,o.kt)("p",null,(0,o.kt)("strong",{parentName:"p"},"Annotation Task")," (see [",(0,o.kt)("a",{parentName:"p",href:"https://docs.google.com/document/d/1mgPTHJWJt1HWmOiM-UQOp-rc8S7zvnkw/edit?usp=sharing&ouid=109871152660798629950&rtpof=true&sd=true"},"Annotation\ninstructions"),"):"),(0,o.kt)("p",null,"+----------------------+----------------------+----------------------+\n| ",(0,o.kt)("strong",{parentName:"p"},"#"),"               | ",(0,o.kt)("strong",{parentName:"p"},"Step"),"             | ",(0,o.kt)("strong",{parentName:"p"},"Sub-step"),"         |\n+======================+======================+======================+\n| 1                    | ",(0,o.kt)("em",{parentName:"p"},"For each frame in   | 1.  "),"Subject ",(0,o.kt)("strong",{parentName:"p"},"has")," |\n|                      | the video, identify  |     > a bounding box |\n|                      | all subjects in the  |     > (bbox):",(0,o.kt)("em",{parentName:"p"},"       |\n|                      | frame and check to   |                      |\n|                      | see if they have     |     a.  "),"Bbox is     |\n|                      | bounding boxes.",(0,o.kt)("em",{parentName:"p"},"     |                      |\n|                      |                      |        > ",(0,o.kt)("strong",{parentName:"em"},"PASSING")," |\n|                      |                      |         > \u2192 Move     |\n|                      |                      |         > onto the   |\n|                      |                      |         > next       |\n|                      |                      |         > subject in |\n|                      |                      |         > the frame")," |\n|                      |                      |                      |\n|                      |                      |     b.  ",(0,o.kt)("em",{parentName:"p"},"Bbox is     |\n|                      |                      |                      |\n|                      |                      |        > ",(0,o.kt)("strong",{parentName:"em"},"FAILING")," |\n|                      |                      |         > \u2192          |\n|                      |                      |                      |\n|                      |                      |     > Adjust/Re-draw |\n|                      |                      |         > the bbox   |\n|                      |                      |         > (making    |\n|                      |                      |         > sure the   |\n|                      |                      |         > right face |\n|                      |                      |         > track is   |\n|                      |                      |         > selected)")," |\n|                      |                      |                      |\n|                      |                      | 2.  ",(0,o.kt)("em",{parentName:"p"},"Subject         |\n|                      |                      |     > ",(0,o.kt)("strong",{parentName:"em"},"doesn't      |\n|                      |                      |     > have")," a bbox  |\n|                      |                      |     > \u2192 Create a new |\n|                      |                      |     > bounding box   |\n|                      |                      |     > and either     |\n|                      |                      |     > assign it a    |\n|                      |                      |     > new track o    |\n|                      |                      |     > merge an       |\n|                      |                      |     > existing face  |\n|                      |                      |     > track."),"        |\n|                      |                      |                      |\n|                      |                      | 3.  ",(0,o.kt)("em",{parentName:"p"},"Bbox does not   |\n|                      |                      |     > capture a face |\n|                      |                      |     > \u2192 Delete       |\n|                      |                      |     > bbox."),"         |\n+----------------------+----------------------+----------------------+\n| ",(0,o.kt)("strong",{parentName:"p"},"Examples:"),"        |                      |                      |\n+----------------------+----------------------+----------------------+\n| ",(0,o.kt)("strong",{parentName:"p"},"Passing")," Bbox     | ","![image.png]",'(media   |                      |\n|                      | /image6.png){width=" |                      |\n|                      | 4.104166666666667in" |                      |\n|                      | height="2.           |                      |\n|                      | 2916666666666665in"} |                      |\n+----------------------+----------------------+----------------------+\n| ',(0,o.kt)("strong",{parentName:"p"},"Failing")," bbox     | ","![image.png]",'(media/  |                      |\n|                      | image12.png){width=" |                      |\n|                      | 4.104166666666667in" |                      |\n|                      | height="2.           |                      |\n|                      | 2916666666666665in"} |                      |\n+----------------------+----------------------+----------------------+\n| ',(0,o.kt)("strong",{parentName:"p"},"Missing")," bbox     | ","![image.png]",'(media/  |                      |\n|                      | image23.png){width=" |                      |\n|                      | 4.104166666666667in" |                      |\n|                      | height="2.           |                      |\n|                      | 2916666666666665in"} |                      |\n+----------------------+----------------------+----------------------+\n| Bbox to be           | ',"![image.png]","(media/  |                      |\n| ",(0,o.kt)("strong",{parentName:"p"},"deleted"),'          | image20.png){width=" |                      |\n|                      | 4.104166666666667in" |                      |\n|                      | height="2.           |                      |\n|                      | 3055555555555554in"} |                      |\n+----------------------+----------------------+----------------------+'),(0,o.kt)("h3",{id:"av-step-2-speaker-labeling-and-av-anchor-extraction"},"AV Step 2: Speaker Labeling and AV anchor extraction"),(0,o.kt)("p",null,(0,o.kt)("strong",{parentName:"p"},"Objective:")," Assign each Face Track",(0,o.kt)("sup",{parentName:"p",id:"fnref-1"},(0,o.kt)("a",{parentName:"sup",href:"#fn-1",className:"footnote-ref"},"1"))," (from Step 1) a 'Person ID'\n(for each new subject which has an interaction with the camera-wearer or\nis present in the camera for 500+ frames)."),(0,o.kt)("p",null,(0,o.kt)("strong",{parentName:"p"},"Annotation Task")," (see [",(0,o.kt)("a",{parentName:"p",href:"https://fb-my.sharepoint.com/:w:/p/sallyyoo/EXSVyiXDcypOjOdvgE24Rq0BmSU2iEDVHDneItZblllefQ?e=1nU14r"},"Annotation\ninstructions"),"):"),(0,o.kt)("p",null,"+----------------------+----------------------+----------------------+\n| ",(0,o.kt)("strong",{parentName:"p"},"#"),"               | ",(0,o.kt)("strong",{parentName:"p"},"Step"),"             | ",(0,o.kt)("strong",{parentName:"p"},"Sub-step"),"         |\n+======================+======================+======================+\n| 1                    | ",(0,o.kt)("em",{parentName:"p"},"Identify the 'Next  | 1.  "),"Toggle On the   |\n|                      | Track' and go to the |     'Out-of-Frame'   |\n|                      | first frame of this  |     Track List",(0,o.kt)("em",{parentName:"p"},"      |\n|                      | track."),"              |                      |\n|                      |                      | 2.  ",(0,o.kt)("em",{parentName:"p"},"Select the next |\n|                      |                      |     Track from the   |\n|                      |                      |     list"),"            |\n|                      |                      |                      |\n|                      |                      | 3.  ",(0,o.kt)("em",{parentName:"p"},"Click 'First    |\n|                      |                      |     Key Frame'"),"      |\n+----------------------+----------------------+----------------------+\n| 2                    | ",(0,o.kt)("em",{parentName:"p"},"Assign this Track a | 1.  "),"Use the drop    |\n|                      | unique 'Person ID'   |     down menu to     |\n|                      | (e.g. Person 1,      |     select a Person  |\n|                      | Person 2, ect)",(0,o.kt)("em",{parentName:"p"},"      |     ID"),"              |\n|                      |                      |                      |\n|                      |                      | 2.  ",(0,o.kt)("em",{parentName:"p"},"Each time this  |\n|                      |                      |     person appears   |\n|                      |                      |     in the video,    |\n|                      |                      |     assign their     |\n|                      |                      |     Track ","#"," to      |\n|                      |                      |     their designated |\n|                      |                      |     Person ID"),"       |\n+----------------------+----------------------+----------------------+\n| 3                    | ",(0,o.kt)("em",{parentName:"p"},"Repeat steps 1-4    |                      |\n|                      | until all tracks     |                      |\n|                      | have Person ID's     |                      |\n|                      | assigned."),"           |                      |\n+----------------------+----------------------+----------------------+\n| ",(0,o.kt)("strong",{parentName:"p"},"Examples:"),"        |                      |                      |\n+----------------------+----------------------+----------------------+\n| [","[AV - Step 2 -      |                      |                      |\n| Person ID Example    |                      |                      |\n| Annot                |                      |                      |\n| ation.mp4]",'(htt |                      |                      |\n| ps://drive.google.co |                      |                      |\n| m/file/d/1R1R1BXXMTx |                      |                      |\n| FsZKl98tM73gIWRrMCZj |                      |                      |\n| O2/view?usp=sharing) |                      |                      |\n|                      |                      |                      |\n| ![](media/           |                      |                      |\n| image26.png){width=" |                      |                      |\n| 6.203125546806649in" |                      |                      |\n| height="2            |                      |                      |\n| .077746062992126in"} |                      |                      |\n+----------------------+----------------------+----------------------+'),(0,o.kt)("h3",{id:"av-step-3-speech-segmentation-per-speaker"},"AV Step 3: Speech Segmentation (Per Speaker)"),(0,o.kt)("p",null,(0,o.kt)("strong",{parentName:"p"},"Objective:")," Label voice activity for all subjects in the video."),(0,o.kt)("p",null,(0,o.kt)("strong",{parentName:"p"},"Annotation Task")," (see [",(0,o.kt)("a",{parentName:"p",href:"https://fb-my.sharepoint.com/:w:/p/sallyyoo/EXSVyiXDcypOjOdvgE24Rq0BmSU2iEDVHDneItZblllefQ?e=1nU14r"},"Annotation\ninstructions"),"):"),(0,o.kt)("p",null,"+----------------------+----------------------+----------------------+\n| ",(0,o.kt)("strong",{parentName:"p"},"#"),"               | ",(0,o.kt)("strong",{parentName:"p"},"Step"),"             | ",(0,o.kt)("strong",{parentName:"p"},"Sub-step"),"         |\n+======================+======================+======================+\n| 1                    | ",(0,o.kt)("em",{parentName:"p"},"Label voice         | 1.  Annotate the     |\n|                      | activity for the     |     video using the  |\n|                      | ",(0,o.kt)("strong",{parentName:"em"},"camera wearer"),"    |     time segment     |\n|                      | first and then for   |     tool\u202f            |\n|                      | each Person ID."),"     |                      |\n|                      |                      | 2.  Start an         |\n|                      |                      |     annotation when  |\n|                      |                      |     a person makes a |\n|                      |                      |     sound (speech,   |\n|                      |                      |     coughing, sigh,  |\n|                      |                      |     ",(0,o.kt)("strong",{parentName:"p"},"any            |\n|                      |                      |     utterance"),").    |\n|                      |                      |                      |\n|                      |                      | 3.  Stop an          |\n|                      |                      |     annotation when  |\n|                      |                      |     a person stops   |\n|                      |                      |     making sounds.   |\n|                      |                      |                      |\n|                      |                      | 4.  Do not stop an   |\n|                      |                      |     annotation if a  |\n|                      |                      |     person starts    |\n|                      |                      |     making sound     |\n|                      |                      |     again within 1   |\n|                      |                      |     second after     |\n|                      |                      |     they stopped     |\n|                      |                      |                      |\n|                      |                      | 5.  Label the        |\n|                      |                      |     segment          |\n|                      |                      |     according to the |\n|                      |                      |     Person ID        |\n|                      |                      |     displayed in the |\n|                      |                      |     bounding box     |\n|                      |                      |     around their     |\n|                      |                      |     head             |\n|                      |                      |                      |\n|                      |                      | 6.  Repeat the       |\n|                      |                      |     process for all  |\n|                      |                      |     sounds made by   |\n|                      |                      |     the people in    |\n|                      |                      |     the video.       |\n+----------------------+----------------------+----------------------+\n| ",(0,o.kt)("strong",{parentName:"p"},"Examples:"),"        |                      |                      |\n+----------------------+----------------------+----------------------+\n| [","[AV - Step 3 -      |                      |                      |\n| Voice Activity       |                      |                      |\n| Annotation           |                      |                      |\n| Ex                   |                      |                      |\n| ample.mp4]",'(htt |                      |                      |\n| ps://drive.google.co |                      |                      |\n| m/file/d/19zHRx6nC-l |                      |                      |\n| i7wC0ivImC5b-KCjLMES |                      |                      |\n| Pt/view?usp=sharing) |                      |                      |\n|                      |                      |                      |\n| ![](media/           |                      |                      |\n| image34.png){width=" |                      |                      |\n| 6.239583333333333in" |                      |                      |\n| height="2            |                      |                      |\n| .236111111111111in"} |                      |                      |\n+----------------------+----------------------+----------------------+'),(0,o.kt)("h3",{id:"av-step-4-transcription"},"AV Step 4: Transcription"),(0,o.kt)("p",null,(0,o.kt)("strong",{parentName:"p"},"Objective:")," Transcribe voice activity for all subjects in the video."),(0,o.kt)("h3",{id:"av-step-5-correcting-speech-transcriptions-wip"},"AV Step 5: Correcting Speech Transcriptions ","[","WIP","]"),(0,o.kt)("p",null,(0,o.kt)("strong",{parentName:"p"},"Objective:")," Correcting Speech Transcription annotation from Step 4."),(0,o.kt)("p",null,(0,o.kt)("strong",{parentName:"p"},"Annotation Task")," (see ",(0,o.kt)("a",{parentName:"p",href:"https://docs.google.com/document/d/1Wi-dRM9sKPtRdjdLIxGYxJYjfU72on3css-8IjrKAOc/edit?usp=sharing"},"Annotation instructions"),"\n","[","WIP","]","):"),(0,o.kt)("p",null,"+---------------+-------------------------+-------------------------+\n| ",(0,o.kt)("strong",{parentName:"p"},"#"),"        | ",(0,o.kt)("strong",{parentName:"p"},"Step"),"                | ",(0,o.kt)("strong",{parentName:"p"},"Sub-step"),"            |\n+===============+=========================+=========================+\n| 0             | ",(0,o.kt)("em",{parentName:"p"},"Pre-load the           | The task begins with    |\n|               | annotation tool."),"       | the pre-load of the     |\n|               |                         | following things:       |\n|               |                         |                         |\n|               |                         | -   Output of AV Step 3 |\n|               |                         |     > (Speech           |\n|               |                         |     > Segmentation per  |\n|               |                         |     > Person ID)        |\n|               |                         |                         |\n|               |                         | -   Output of AV Step 4 |\n|               |                         |     > (Human            |\n|               |                         |     > transcriptions)   |\n|               |                         |                         |\n|               |                         | -   Automatic           |\n|               |                         |     > transcriptions    |\n|               |                         |     > from ASR          |\n|               |                         |     > algorithms.       |\n+---------------+-------------------------+-------------------------+\n| 1             | ",(0,o.kt)("em",{parentName:"p"},"For each human         | For each person with    |\n|               | transcription chunk,    | the active voice        |\n|               | identify the            | activity:               |\n|               | corresponding person    |                         |\n|               | IDs with voice activity | -   Listen to the video |\n|               | on"),"                     |                         |\n|               |                         | -   If the person's     |\n|               |                         |     > speech is = to    |\n|               |                         |     > the content in    |\n|               |                         |     > the transcription |\n|               |                         |     > chunk, then copy  |\n|               |                         |     > this speech       |\n|               |                         |     > content from      |\n|               |                         |     > transcript into a |\n|               |                         |     > new dialog        |\n|               |                         |     > box/tag that      |\n|               |                         |     > corresponds to    |\n|               |                         |     > the person.       |\n+---------------+-------------------------+-------------------------+\n| 2             | ",(0,o.kt)("em",{parentName:"p"},"Repeat Step 1 for the  |                         |\n|               | machine generated       |                         |\n|               | transcription chunks."),"  |                         |\n+---------------+-------------------------+-------------------------+\n| ",(0,o.kt)("strong",{parentName:"p"},"Examples:")," |                         |                         |\n+---------------+-------------------------+-------------------------+\n| TBU           |                         |                         |\n+---------------+-------------------------+-------------------------+"),(0,o.kt)("h3",{id:"social-step-1-camera-wearer-attention"},"Social Step 1: Camera-Wearer Attention"),(0,o.kt)("p",null,(0,o.kt)("strong",{parentName:"p"},"Objective"),": Annotate temporal segments in which a person is looking\nat the camera wearer."),(0,o.kt)("p",null,(0,o.kt)("strong",{parentName:"p"},"Annotation Task")," (see [",(0,o.kt)("a",{parentName:"p",href:"https://docs.google.com/document/d/1CqgM73xrYuva5eKSfTmM4Tby7tso1jXX/edit?usp=sharing&ouid=109871152660798629950&rtpof=true&sd=true"},"Annotation\ninstructions"),"):"),(0,o.kt)("p",null,"+----------------------+----------------------+----------------------+\n| ",(0,o.kt)("strong",{parentName:"p"},"#"),"               | ",(0,o.kt)("strong",{parentName:"p"},"Step"),"             | ",(0,o.kt)("strong",{parentName:"p"},"Sub-step"),"         |\n+======================+======================+======================+\n| 1                    | ",(0,o.kt)("em",{parentName:"p"},"Watch the video and |                      |\n|                      | find the time when   |                      |\n|                      | someone is looking   |                      |\n|                      | at the camera        |                      |\n|                      | wearer"),"              |                      |\n+----------------------+----------------------+----------------------+\n| 2                    | ",(0,o.kt)("em",{parentName:"p"},"Annotate the time   | 1.  Start an         |\n|                      | segment using the    |     annotation when  |\n|                      | time segment tool:\u202f")," |     a person start   |\n|                      |                      |     to look at the   |\n|                      |                      |     camera wearer    |\n|                      |                      |                      |\n|                      |                      | 2.  Stop an          |\n|                      |                      |     annotation when  |\n|                      |                      |     a person stops   |\n|                      |                      |     looking at the   |\n|                      |                      |     camera wearer    |\n|                      |                      |                      |\n|                      |                      | 3.  Label the        |\n|                      |                      |     segment          |\n|                      |                      |     according to the |\n|                      |                      |     Person ID        |\n|                      |                      |     displayed in the |\n|                      |                      |     bounding box     |\n|                      |                      |     around their     |\n|                      |                      |     head             |\n|                      |                      |                      |\n|                      |                      | 4.  Repeat the       |\n|                      |                      |     process for all  |\n|                      |                      |     cases in the     |\n|                      |                      |     video.           |\n+----------------------+----------------------+----------------------+\n| ",(0,o.kt)("strong",{parentName:"p"},"Examples:"),"        |                      |                      |\n+----------------------+----------------------+----------------------+\n| [","[social_annotation  |                      |                      |\n| _demo.mp4]",'(htt |                      |                      |\n| ps://drive.google.co |                      |                      |\n| m/file/d/10Z0Ge0bIXJ |                      |                      |\n| NbhUZ61iT0bckCj1Vno- |                      |                      |\n| G7/view?usp=sharing) |                      |                      |\n|                      |                      |                      |\n| ![](media/           |                      |                      |\n| image17.png){width=" |                      |                      |\n| 6.239583333333333in" |                      |                      |\n| height="3.           |                      |                      |\n| 3775820209973753in"} |                      |                      |\n+----------------------+----------------------+----------------------+'),(0,o.kt)("h3",{id:"social-step-2-speech-target-classification"},"Social Step 2: Speech Target Classification"),(0,o.kt)("p",null,(0,o.kt)("strong",{parentName:"p"},"Objective"),": Given already annotated AV Voice Activity segmentation,\nthe annotator is going to annotate the particular speech segments in\nwhich the person is talking to the camera wearer."),(0,o.kt)("p",null,(0,o.kt)("strong",{parentName:"p"},"Annotation Task")," (see ",(0,o.kt)("a",{parentName:"p",href:"https://docs.google.com/document/d/1wnJqZESJpQrwaCkdFZWm8Makmb5bF4r5/edit?usp=sharing&ouid=109871152660798629950&rtpof=true&sd=true"},"Annotation instructions"),"):"),(0,o.kt)("p",null,"+----------------------+----------------------+----------------------+\n| ",(0,o.kt)("strong",{parentName:"p"},"#"),"               | ",(0,o.kt)("strong",{parentName:"p"},"Step"),"             | ",(0,o.kt)("strong",{parentName:"p"},"Sub-step"),"         |\n+======================+======================+======================+\n| 1                    | ",(0,o.kt)("em",{parentName:"p"},"Watch the video     |                      |\n|                      | with AV voice        |                      |\n|                      | segmentation results |                      |\n|                      | (start-end time,     |                      |\n|                      | person ID)"),"          |                      |\n+----------------------+----------------------+----------------------+\n| 2                    | ",(0,o.kt)("em",{parentName:"p"},"Annotate segments   | 1.  "),"Identify a      |\n|                      | where someone is     |     > segment in     |\n|                      | talking to the       |     > which someone  |\n|                      | camera wearer",(0,o.kt)("em",{parentName:"p"},"       |     > is talking to  |\n|                      |                      |     > the camera     |\n|                      | "),"Repeat the process  |     > wearer",(0,o.kt)("em",{parentName:"p"},"        |\n|                      | for all cases in the |                      |\n|                      | video."),"              | 2.  ",(0,o.kt)("em",{parentName:"p"},"Click the time  |\n|                      |                      |     > segment, then  |\n|                      |                      |     > you can see    |\n|                      |                      |     > the Voice      |\n|                      |                      |     > activity       |\n|                      |                      |     > annotation     |\n|                      |                      |     > information on |\n|                      |                      |     > the left side  |\n|                      |                      |     > bar."),"          |\n|                      |                      |                      |\n|                      |                      | 3.  ",(0,o.kt)("em",{parentName:"p"},'Click the drop  |\n|                      |                      |     > down box below |\n|                      |                      |     > the "Target of |\n|                      |                      |                      |\n|                      |                      |  > Speech"'),'![](media |\n|                      |                      | /image8.png){width=" |\n|                      |                      | 3.198122265966754in" |\n|                      |                      |     > height="1      |\n|                      |                      | .030867235345582in"} |\n|                      |                      |                      |\n|                      |                      | 4.  ',(0,o.kt)("em",{parentName:"p"},'In the dropdown |\n|                      |                      |     > menu, select   |\n|                      |                      |                      |\n|                      |                      |    > "Camera-Wearer" |\n|                      |                      |     > if the speech  |\n|                      |                      |     > is only toward |\n|                      |                      |     > the camera     |\n|                      |                      |     > wearer.'),"       |\n|                      |                      |                      |\n|                      |                      | 5.  ",(0,o.kt)("em",{parentName:"p"},'Choose          |\n|                      |                      |     > "Camera-Wearer |\n|                      |                      |     > and others" if |\n|                      |                      |     > the speech     |\n|                      |                      |     > segment is     |\n|                      |                      |     > toward         |\n|                      |                      |     > multiple       |\n|                      |                      |     > people         |\n|                      |                      |     > including the  |\n|                      |                      |     > camera wearer  |\n|                      |                      |     > (e.g., talking |\n|                      |                      |     > to multiple    |\n|                      |                      |     > audience       |\n|                      |                      |     > members).'),"     |\n|                      |                      |                      |\n|                      |                      | 6.  ",(0,o.kt)("em",{parentName:"p"},"Repeat the      |\n|                      |                      |     > process for    |\n|                      |                      |     > all relevant   |\n|                      |                      |     > segments."),"     |\n+----------------------+----------------------+----------------------+\n| ",(0,o.kt)("strong",{parentName:"p"},"Examples:"),"        |                      |                      |\n+----------------------+----------------------+----------------------+\n| [","[social_step2_ex    |                      |                      |\n| ample.mp4]",'(htt |                      |                      |\n| ps://drive.google.co |                      |                      |\n| m/file/d/1KUuaEr86sa |                      |                      |\n| nTGI0-oNAYlgrvxru1TN |                      |                      |\n| fw/view?usp=sharing) |                      |                      |\n|                      |                      |                      |\n| ![](media/           |                      |                      |\n| image40.png){width=" |                      |                      |\n| 6.239583333333333in" |                      |                      |\n| height="3.           |                      |                      |\n| 6666666666666665in"} |                      |                      |\n+----------------------+----------------------+----------------------+'),(0,o.kt)("table",null,(0,o.kt)("tr",null,(0,o.kt)("td",null),(0,o.kt)("td",null))))}d.isMDXComponent=!0},2914:function(e,t,n){t.Z=n.p+"assets/images/image1-cb95f7a6ce8d8cc57a8a376a4870bd4b.png"},8622:function(e,t,n){t.Z=n.p+"assets/images/image10-a15f59ac4828168c130fc993a5dba16d.png"},287:function(e,t,n){t.Z=n.p+"assets/images/image13-1dbe07a190ef030848b79fe86ab52b9f.png"},3299:function(e,t,n){t.Z=n.p+"assets/images/image14-168aa13b5d867f63500a67faa6de9f14.png"},6900:function(e,t,n){t.Z=n.p+"assets/images/image16-9e55f40cbd0b57fc516ff43a2d52324d.png"},1451:function(e,t,n){t.Z=n.p+"assets/images/image18-fec68ada7e115e2b5ddad1b313a3d283.png"},9850:function(e,t,n){t.Z=n.p+"assets/images/image19-00e19a2a62a562005bd744ae7965764a.png"},3915:function(e,t,n){t.Z=n.p+"assets/images/image2-73d744aacb706a6c6be825d0f333a008.png"},3835:function(e,t,n){t.Z=n.p+"assets/images/image21-997834909d39c1d2ea8729613e8cf735.png"},5499:function(e,t,n){t.Z=n.p+"assets/images/image3-db38883c4c8f547284a969c5d3197adf.png"},2140:function(e,t,n){t.Z=n.p+"assets/images/image31-219567f3e6b0e31e8b839676ab8fafbb.png"},7064:function(e,t,n){t.Z=n.p+"assets/images/image32-8b0a8c1616304b84176927470f098846.png"},874:function(e,t,n){t.Z=n.p+"assets/images/image33-930945bc750e68e528ae8219b42fce82.png"},4850:function(e,t,n){t.Z=n.p+"assets/images/image35-91b5eb2d1a6d9ba45ec1f3bba497a145.png"},1266:function(e,t,n){t.Z=n.p+"assets/images/image38-80d977484213083a627b3a0d642d91b4.jpg"},6217:function(e,t,n){t.Z=n.p+"assets/images/image4-8e3ced36f3852c4e3022c81523a33885.png"},7458:function(e,t,n){t.Z=n.p+"assets/images/image42-9e5ac4e4b20ec34bb336528981701d9a.png"},9799:function(e,t,n){t.Z=n.p+"assets/images/image43-7929512eb1545fa9915c9f6261447238.png"},2287:function(e,t,n){t.Z=n.p+"assets/images/image44-35c45438632a232cfa14668d3b427e51.png"},7301:function(e,t,n){t.Z=n.p+"assets/images/image45-4154b0e8b1843819b876742ac2343582.png"},7824:function(e,t,n){t.Z=n.p+"assets/images/image5-1c194e80ab2a55776812a699b248b5ee.png"},4273:function(e,t,n){t.Z=n.p+"assets/images/image7-e0a2bd6a7b876b3194e9a7bbf876256c.png"}}]);